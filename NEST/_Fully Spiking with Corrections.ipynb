{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fcf8ab5-b322-4989-99f8-9da3ee245fcc",
   "metadata": {},
   "source": [
    "## Imports and simulation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5066f6-b83b-48d8-8008-76e9badaaae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import nest as sim\n",
    "import numpy as np\n",
    "import pandas\n",
    "from collections import Counter\n",
    "import time as tm\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "from time import sleep, process_time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sim.ResetKernel()\n",
    "\n",
    "mins = 10.\n",
    "sim_len = int(mins * 60000)\n",
    "print(f'simulation length: {mins} mins = {sim_len} ms')\n",
    "sim.local_num_threads = 8 # NEST recommends 1 thread per core\n",
    "\n",
    "# 'simulate': Run on NEST to generate results, this will save the results to .npy files\n",
    "# 'load': Load a prior run without running the NEST simulator\n",
    "\n",
    "simulate_or_load = 'simulate'\n",
    "\n",
    "# 'spiral': Generate a spiral trajectory\n",
    "# 'rat': Load one or more Sargolini datasets from file\n",
    "\n",
    "spiral_or_rat = 'rat'\n",
    "concatenate_rat = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde83c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population cell counts\n",
    "\n",
    "# N_ex: number of cells in the excitatory rings\n",
    "# N_in: number of cells in the inhibitory rings\n",
    "# N_cj: number of cells in the conjunctive rings\n",
    "# rings: number of mono-axis rings ('directional rings')\n",
    "# omni_rings: number of axis-invariant rings ('speed rings')\n",
    "# window_size: how large a window of excitatory ring cells is each principle axis cell sensitive to?\n",
    "# N_pa_cells_per_ring: how many PA cells exist for each ring (more = finer binning of excitatory ring activity)\n",
    "# N_pyramidals: how many pyramidal cells are there?\n",
    "\n",
    "calibration_mode = False # Set input to 0, to study static ring\n",
    "corrections = True\n",
    "\n",
    "N_ex = 120\n",
    "N_in = N_ex\n",
    "N_cj = N_ex\n",
    "\n",
    "rings = 3\n",
    "omni_rings = 0\n",
    "\n",
    "window_size = 5\n",
    "\n",
    "N_pa_cells_per_ring = N_ex // window_size\n",
    "\n",
    "N_pyramidals = N_pa_cells_per_ring ** rings\n",
    "\n",
    "tension = True\n",
    "\n",
    "minimum_input = 2700#675#2000#1000\n",
    "\n",
    "# Connection Gaussian weight parameters\n",
    "\n",
    "# sigma: variance for excitatory ring -> inhibitory ring weight Gaussian\n",
    "# in_sigma: variance for inhibitory ring -> excitatory ring weight Gaussian\n",
    "# in_cj_sigma: variance for inhibitory ring -> conjunctive rings weight Gaussian\n",
    "# mu: mean offset of Gaussians (when used)\n",
    "# prune_smaller_than: weights below this threshold will become 0, effectively removing the connection\n",
    "\n",
    "sigma = 0.1#0.12#0.1\n",
    "in_sigma = 0.1\n",
    "in_cj_sigma = 0.09375#0.075#0.095#0.0925#0.08#0.09#0.08 # was at about 1-1.02 before, when coming back to this, give these a try\n",
    "mu = 0.5\n",
    "prune_smaller_than = 10\n",
    "\n",
    "smooth_sigma = 10\n",
    "\n",
    "# Connection scalar weight parameters. These are signed as appropriate later on\n",
    "\n",
    "# base_ex: excitatory ring -> inhibitory ring weight strength (+)\n",
    "# base_in: inhibitory ring -> excitatory ring weight strength (-)\n",
    "# base_cj: conjunctive rings -> excitatory rings weight strength (+)\n",
    "# w_ex_cj: excitatory rings -> conjunctive rings weight strength (+)\n",
    "# w_in_cj: inhibitory_rings -> conjunctive rings weight strength (-)\n",
    "# w_ex_pa: excitatory_rings -> principle axis cells weight strength (+)\n",
    "# w_pa_py: principle axis cells -> pyramidal cells weight strength (+)\n",
    "\n",
    "# Spiral settings:\n",
    "\n",
    "# base_ex = 5000\n",
    "# base_in = 1500\n",
    "# base_cj = 500\n",
    "# w_ex_cj = 440\n",
    "# w_in_cj = 1800 # Was about 800 before, put up a lot higher before velocity calculation was changed to properly share out input\n",
    "# w_ex_pa = 300\n",
    "# w_pa_py = 200\n",
    "\n",
    "# Rat settings:\n",
    "\n",
    "# Next week: dropping inhibition is helping with integrating small velocities, try to lower it further and lower excitation too if needs be\n",
    "\n",
    "base_ex = 1750#4000#5000\n",
    "base_in = 0#5000#1500\n",
    "base_cj = 500\n",
    "w_ex_cj = 0\n",
    "w_in_cj = 3000#3500#4000#4500#3600#1700#700 # Was about 800 before, put up a lot higher before velocity calculation was changed to properly share out input\n",
    "w_ex_pa = 100#80\n",
    "w_pa_py = 300\n",
    "w_in_pa = 1000\n",
    "\n",
    "cj_in_offset = 0 # Is the inhibitory 'bowl' biased towards the direction of input? If so, by how many cells?\n",
    "\n",
    "# Synaptic transmission delay (I believe this includes the synapse proper and action potential travel time)\n",
    "\n",
    "delay = 0.1\n",
    "\n",
    "# Velocity scaling parameters\n",
    "\n",
    "# I_vel: multiply incoming velocity by this amount to get the input current representing the vestibular signal\n",
    "# velocity_threshold: Are very small values for velocity set to zero?\n",
    "# miniumum_velocity: What is the minimum non-zero velocity? (only works if velocity_threshold is True)\n",
    "\n",
    "I_vel = 2000000#800 # Seems to work best if you can get the velocities in a 0-4000 range\n",
    "\n",
    "# Are conjuctive cells synapsed onto by excitatory layer or inhibitory layer.\n",
    "\n",
    "# 'positive': scalar excitatory weight, conjunctive weights must be tuned to act as a coincidence detector for input velocity and bump activity\n",
    "# 'negative': Gaussian inhibitory weight, suppresses incoming velocity input too far from the attractor bump\n",
    "# 'both': inhibitory 'bowl' as per 'negative' and self-reinforcing excitatory connections\n",
    "\n",
    "conjunctive_mode = 'negative'\n",
    "\n",
    "# Intrinsic excitation of the excitatory ring, constant current in picoamps\n",
    "\n",
    "intrinsic_excitation = 0.#225.\n",
    "\n",
    "theta = False\n",
    "\n",
    "# Initial (bump-forming) current injection parameters. This is a short spike of input to form the initial attractor state, to be adjusted by conjunctive input\n",
    "\n",
    "# I_init: strength of input current in picoamps\n",
    "# I_init_dur: how long this is applied for, in milliseconds\n",
    "# I_init_pos: where is this applied, in ring index (1-120). NEST, for better or worse, has neuron IDs starting at 1\n",
    "\n",
    "I_init = 350.0#300.0\n",
    "I_init_dur = 100.0\n",
    "I_init_pos = 60 - 1#(N_ex - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df326941-686c-4182-8316-7f5dc8d0ae50",
   "metadata": {},
   "source": [
    "## Create neuron populations from the above parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b6c9f-215a-4078-b680-a4fd7dabdda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store each ring's population\n",
    "\n",
    "exc = []\n",
    "inh = []\n",
    "l = []\n",
    "r = []\n",
    "pa_cells = []\n",
    "#input_pa_cells = []\n",
    "\n",
    "for i in range(rings):\n",
    "    \n",
    "    if intrinsic_excitation > 0:\n",
    "\n",
    "        exc.append(sim.Create(\"iaf_psc_alpha\",N_ex, params={\"I_e\": intrinsic_excitation})) # Excitatory layer, with intrinsic activity\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        exc.append(sim.Create(\"iaf_psc_alpha\",N_ex))\n",
    "        \n",
    "    inh.append(sim.Create(\"iaf_psc_alpha\",N_in)) # Inhibitory layer\n",
    "\n",
    "    l.append(sim.Create(\"iaf_psc_alpha\",N_cj)) # Conjunctive layer for left turn\n",
    "    r.append(sim.Create(\"iaf_psc_alpha\",N_cj)) # Conjunctive layer for right turn\n",
    "    \n",
    "    pa_cells.append(sim.Create(\"iaf_psc_alpha\",N_pa_cells_per_ring))\n",
    "    \n",
    "    #input_pa_cells.append(sim.Create(\"iaf_psc_alpha\",N_pa_cells_per_ring))\n",
    "    \n",
    "# The pyramidal cells associate across rings    \n",
    "\n",
    "pyramidal_cells = sim.Create(\"iaf_psc_alpha\",N_pyramidals)\n",
    "\n",
    "input_grid_devices = sim.Create('step_current_generator',N_pyramidals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9cfc2a-2cb6-4fa4-972f-8d6637e78f55",
   "metadata": {},
   "source": [
    "## Define connection weight matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty matrices\n",
    "\n",
    "w_ex = np.empty((N_in,N_ex))\n",
    "w_in = np.empty((N_ex,N_in))\n",
    "\n",
    "for e in range(N_ex):\n",
    "    for i in range(N_in):\n",
    "        # Find minimum (true) distance between adjacent cells\n",
    "        d1 = abs(e/N_ex - i/N_in)\n",
    "        d2 = abs(e/N_ex - i/N_in -1)\n",
    "        d3 = abs(e/N_ex - i/N_in +1)\n",
    "        d = min(abs(d1),abs(d2),abs(d3))\n",
    "        # Create gaussian value based on parameters above to define connection strengths\n",
    "        w_gauss = np.exp(-(d - mu)**2/2/sigma**2) # Exitatory -> inhibitory\n",
    "        w_ring = np.exp(-(d)**2/2/in_sigma**2) # Inhibitory -> excitatory\n",
    "        # Assign appropriate weight values to matrices\n",
    "        w_ex[i,e] = base_ex * w_gauss\n",
    "        w_in[e,i] = base_in * w_ring \n",
    "    \n",
    "# Very small weights become 0\n",
    "\n",
    "w_ex[w_ex<prune_smaller_than] = 0\n",
    "w_in[w_in<prune_smaller_than] = 0\n",
    "\n",
    "# Plot weight matrix interactions as a sanity check. Should be an 'arch' of inhibition, leaving the suppressing areas far from the injection site\n",
    "\n",
    "intrinsic_input = np.tile(450., N_ex)\n",
    "\n",
    "injection_site = I_init_pos\n",
    "\n",
    "plt.plot(w_ex[injection_site, :])\n",
    "plt.vlines(injection_site, 0, np.max(w_ex), color = 'red')\n",
    "plt.title(\"w_ex\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(-w_in[injection_site, :])\n",
    "plt.vlines(injection_site, 0, np.min(-w_in), color = 'red')\n",
    "plt.title(\"w_in\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(w_ex[injection_site, :] * -w_in[:, :])\n",
    "plt.vlines(injection_site, 0, np.min(w_ex[injection_site, :] * -w_in))\n",
    "plt.title(\"Inhibition Shape (w_ex * w_in)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746bf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, connection weight matrices, this time between conjunctive layers and the excitatory layer\n",
    "\n",
    "w_l = np.empty((N_ex,N_cj))\n",
    "w_r = np.empty((N_ex,N_cj))\n",
    "\n",
    "for c in range(N_cj):  \n",
    "    for e in range(N_ex):\n",
    "        # Minimum distance, this time between each conjunctive cell and the excitatory cell displaced 1 away (e +/- 1)\n",
    "        # Left is anticlockwise, therefore drives the cell immediately to the left\n",
    "        # Right is clockwise, therefore drives the cell immediately to the right\n",
    "        d1 = abs((e-1)/N_cj - c/N_ex)\n",
    "        d2 = abs((e-1)/N_cj - c/N_ex -1)\n",
    "        d3 = abs((e-1)/N_cj - c/N_ex +1)\n",
    "        d = min(abs(d1),abs(d2),abs(d3))\n",
    "        w_l[e,c] = base_cj * (np.exp(-(d)**2/2/sigma**2))\n",
    "        \n",
    "        d1 = abs((e+1)/N_cj - c/N_ex)\n",
    "        d2 = abs((e+1)/N_cj - c/N_ex -1)\n",
    "        d3 = abs((e+1)/N_cj - c/N_ex +1)\n",
    "        d = min(abs(d1),abs(d2),abs(d3))\n",
    "        w_r[e,c] = base_cj * (np.exp(-(d)**2/2/sigma**2))\n",
    "\n",
    "# Set all not the max to zero; makes sure the conjunctive cells only drive the immediate neighbour\n",
    "# Still uses the Gaussian connection weight, just doesn't use the whole Gaussian (for now)\n",
    "\n",
    "m = np.amax(w_l)\n",
    "w_l[w_l<m] = 0\n",
    "m = np.amax(w_r)\n",
    "w_r[w_r<m] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219b3c2-f017-409c-960d-f49e637408d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian weight matrix for inhibitory->left conjunctive cells (if conjuctive_mode == 'negative')\n",
    "\n",
    "w_in_l_cj_gauss = np.empty((N_cj,N_in))\n",
    "\n",
    "for i in range(N_in):\n",
    "    for c in range(N_cj):  \n",
    "        # Minimum distance, this time between each conjunctive cell and the excitatory cell displaced 1 away (e +/- 1)\n",
    "        # Left is anticlockwise, therefore drives the cell immediately to the left\n",
    "        # Right is clockwise, therefore drives the cell immediately to the right\n",
    "        d1 = abs((c-cj_in_offset)/N_cj - i/N_in)\n",
    "        d2 = abs((c-cj_in_offset)/N_cj - i/N_in -1)\n",
    "        d3 = abs((c-cj_in_offset)/N_cj - i/N_in +1)\n",
    "        d = min(abs(d1),abs(d2),abs(d3))\n",
    "        w_in_l_cj_gauss[c,i] = w_in_cj * (np.exp(-(d)**2/2/in_cj_sigma**2))\n",
    "        \n",
    "w_in_l_cj_gauss = w_in_l_cj_gauss# - np.max(w_in_cj_gauss)\n",
    "\n",
    "# Very small weights become 0\n",
    "\n",
    "w_in_l_cj_gauss[w_in_l_cj_gauss<prune_smaller_than] = 0\n",
    "w_in_l_cj_gauss[w_in_l_cj_gauss<prune_smaller_than] = 0\n",
    "\n",
    "plt.plot(-w_in_l_cj_gauss[0, :])\n",
    "plt.title(\"w_in_l_cj_gauss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot( w_ex[injection_site, :] * -w_in_l_cj_gauss[:, :])\n",
    "plt.title(\"Conjunctive Inhibition (w_ex * w_in_l_cj_gauss)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737c1f09-bb40-4e72-9de4-d907163c028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian weight matrix for inhibitory->right conjunctive cells (if conjuctive_mode == 'negative')\n",
    "\n",
    "w_in_r_cj_gauss = np.empty((N_cj,N_in))\n",
    "\n",
    "for i in range(N_in):\n",
    "    for c in range(N_cj):  \n",
    "        # Minimum distance, this time between each conjunctive cell and the excitatory cell displaced 1 away (e +/- 1)\n",
    "        # Left is anticlockwise, therefore drives the cell immediately to the left\n",
    "        # Right is clockwise, therefore drives the cell immediately to the right\n",
    "        d1 = abs((c+cj_in_offset)/N_cj - i/N_in)\n",
    "        d2 = abs((c+cj_in_offset)/N_cj - i/N_in -1)\n",
    "        d3 = abs((c+cj_in_offset)/N_cj - i/N_in +1)\n",
    "        d = min(abs(d1),abs(d2),abs(d3))\n",
    "        w_in_r_cj_gauss[c,i] = w_in_cj * (np.exp(-(d)**2/2/in_cj_sigma**2))\n",
    "        \n",
    "w_in_r_cj_gauss = w_in_r_cj_gauss# - np.max(w_in_cj_gauss)\n",
    "\n",
    "# Very small weights become 0\n",
    "\n",
    "w_in_r_cj_gauss[w_in_r_cj_gauss<prune_smaller_than] = 0\n",
    "w_in_r_cj_gauss[w_in_r_cj_gauss<prune_smaller_than] = 0\n",
    "    \n",
    "plt.plot(-w_in_r_cj_gauss[0, :])\n",
    "plt.title(\"w_in_r_cj_gauss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot( w_ex[injection_site, :] * -w_in_r_cj_gauss[:, :])\n",
    "plt.title(\"Conjunctive Inhibition (w_ex * w_in_r_cj_gauss)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d270f60e-4fe1-4d60-97a0-4162c502543f",
   "metadata": {},
   "source": [
    "## Wire everything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cbe7c-1651-4b5e-86fa-b7999aca71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(rings):\n",
    "\n",
    "    # Excitatory and inhibitory set to connect all to all, using the prior calculated weight matrix\n",
    "\n",
    "    exc_2_inh = sim.Connect(exc[i],inh[i],'all_to_all',syn_spec={'weight': w_ex, 'delay': delay})\n",
    "    inh_2_exc = sim.Connect(inh[i],exc[i],'all_to_all',syn_spec={'weight': -w_in, 'delay': delay})\n",
    "    \n",
    "    # Conjunctive layers connecting to the excitatory layer, with weights\n",
    "\n",
    "    l_2_exc = sim.Connect(l[i],exc[i],'all_to_all',syn_spec={'weight': w_l, 'delay': delay})\n",
    "    r_2_exc = sim.Connect(r[i],exc[i],'all_to_all',syn_spec={'weight': w_r, 'delay': delay})\n",
    "    \n",
    "    if conjunctive_mode == 'positive':\n",
    "\n",
    "        # Excitatory connecting one-to-one to both conjuntive layers, with fixed weight.  A 'coincidence detector'.\n",
    "\n",
    "        exc_2_l = sim.Connect(exc[i],l[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "        exc_2_r = sim.Connect(exc[i],r[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "\n",
    "    elif conjunctive_mode == 'negative':\n",
    "\n",
    "        # Inhibitory connecting one-all_to_all-one to both conjuntive layers, with inverse Gaussian weights\n",
    "\n",
    "        inh_2_l = sim.Connect(inh[i],l[i],'all_to_all',syn_spec={'weight': -w_in_l_cj_gauss, 'delay': delay})\n",
    "        inh_2_r = sim.Connect(inh[i],r[i],'all_to_all',syn_spec={'weight': -w_in_r_cj_gauss, 'delay': delay})\n",
    "        \n",
    "    elif conjunctive_mode == 'both':\n",
    "\n",
    "        exc_2_l = sim.Connect(exc[i],l[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "        exc_2_r = sim.Connect(exc[i],r[i],'one_to_one',syn_spec={'weight': w_ex_cj, 'delay': delay})\n",
    "\n",
    "        inh_2_l = sim.Connect(inh[i],l[i],'all_to_all',syn_spec={'weight': -w_in_l_cj_gauss, 'delay': delay})\n",
    "        inh_2_r = sim.Connect(inh[i],r[i],'all_to_all',syn_spec={'weight': -w_in_r_cj_gauss, 'delay': delay})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a7869-7023-41bd-83fa-b5017b3958a4",
   "metadata": {},
   "source": [
    "## Wire everything up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9926bbf1-71d0-4b6f-8f4a-30f593fa31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect a N-wide window of the ring to each principle axis cell\n",
    "\n",
    "import random\n",
    "\n",
    "windows = []\n",
    "\n",
    "for ring in exc:\n",
    "\n",
    "    for i in range(0, N_ex, window_size):\n",
    "    \n",
    "        window = ring[i:i+window_size]\n",
    "        \n",
    "        windows.append(window)\n",
    "\n",
    "for i in range(rings):\n",
    "    \n",
    "    for j in range(N_pa_cells_per_ring):\n",
    "    \n",
    "        sim.Connect(windows[i*N_pa_cells_per_ring+j], [pa_cells[i][j]],'all_to_all',syn_spec={'weight': w_ex_pa, 'delay': delay})\n",
    "        \n",
    "# for i in range(rings):\n",
    "    \n",
    "#     for j in range(N_pa_cells_per_ring):\n",
    "    \n",
    "#         sim.Connect([input_pa_cells[i][j]], windows[i*N_pa_cells_per_ring+j],'all_to_all',syn_spec={'weight': w_ex_pa, 'delay': delay})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4ed73-3a7e-420e-9734-630943036dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each and every combination of the ring neurons ([1,1,1], [1,1,2] ... [N, N, N]), assigning each trio to a pyramidal cell\n",
    "# When all is said and done, this acts like a 3-digit, base-12 number, with each digit representing a ring\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "total_pa_cells = N_pa_cells_per_ring * rings\n",
    "\n",
    "cell_indices = np.zeros(shape = (N_pyramidals))\n",
    "target_cells = np.zeros(shape = (N_pyramidals))\n",
    "source_pa_cells = np.zeros(shape = (rings, N_pyramidals))\n",
    "source_pa_cell_indices = np.zeros(shape = (rings, N_pyramidals))\n",
    "\n",
    "in_range = True\n",
    "\n",
    "for r1 in (x for x in range(N_pa_cells_per_ring) if in_range is True): # Ring 1\n",
    "\n",
    "    for r2 in (y for y in range(N_pa_cells_per_ring) if in_range is True): # Ring 2\n",
    "\n",
    "        for r3 in (z for z in range(N_pa_cells_per_ring) if in_range is True): # Ring 3\n",
    "\n",
    "            cell_index = (r1 * N_pa_cells_per_ring ** 2) + (r2 * N_pa_cells_per_ring) + r3 # Steps from 0 to max\n",
    "            \n",
    "            if cell_index != N_pyramidals:\n",
    "\n",
    "                target_cell = pyramidal_cells[cell_index]\n",
    "\n",
    "                sim.Connect([pa_cells[0][r1]], [target_cell],'all_to_all',syn_spec={'weight': w_pa_py, 'delay': delay})\n",
    "                sim.Connect([pa_cells[1][r2]], [target_cell],'all_to_all',syn_spec={'weight': w_pa_py, 'delay': delay})\n",
    "                sim.Connect([pa_cells[2][r3]], [target_cell],'all_to_all',syn_spec={'weight': w_pa_py, 'delay': delay})\n",
    "\n",
    "                # Gather up data for Pandas, to be used later in grid cell evalutation\n",
    "                \n",
    "                cell_indices[cell_index] = cell_index\n",
    "                target_cells[cell_index] = target_cell\n",
    "                source_pa_cells[0][cell_index] = pa_cells[0][r1]\n",
    "                source_pa_cells[1][cell_index] = pa_cells[1][r2]\n",
    "                source_pa_cells[2][cell_index] = pa_cells[2][r3]\n",
    "                source_pa_cell_indices[0][cell_index] = r1\n",
    "                source_pa_cell_indices[1][cell_index] = r2\n",
    "                source_pa_cell_indices[2][cell_index] = r3\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 in_range = False\n",
    "                \n",
    "pa_to_pyramidal_connections = pd.DataFrame({'Target Cell Index': cell_indices,\n",
    "                                            'Target Pyramidal Cell': target_cells,\n",
    "                                            'Ring 1 Index': source_pa_cell_indices[0],\n",
    "                                            'Ring 2 Index': source_pa_cell_indices[1],\n",
    "                                            'Ring 3 Index': source_pa_cell_indices[2],\n",
    "                                            'Ring 1 PA Cell': source_pa_cells[0],\n",
    "                                            'Ring 2 PA Cell': source_pa_cells[1],\n",
    "                                            'Ring 3 PA Cell': source_pa_cells[2],})\n",
    "\n",
    "print(pa_to_pyramidal_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95e16f-3867-4909-9e3a-24bb7b0756fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same but in the opposite direction; assign each unique combination of RP cells an incoming 'grid input cell'\n",
    "# that can be driven by external input cues\n",
    "\n",
    "# For convenience, and to save modelling an extra population of 'pass through' cells, input devices current synapse directly onto the \n",
    "# excitatory ring, at the midpoint of the RP receptive field\n",
    "\n",
    "# The non-existent input RP cells are given here as placeholders, for managing input to the ring in the format plausible for \n",
    "# downstream brain areas to be aware of; it is assumed that the state of the rings themselves is too granular\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "total_pa_cells = N_pa_cells_per_ring * rings\n",
    "\n",
    "source_cell_indices = np.zeros(shape = (N_pyramidals))\n",
    "source_cells = np.zeros(shape = (N_pyramidals))\n",
    "target_ring_cells = np.zeros(shape = (rings, N_pyramidals))\n",
    "target_ring_cell_indices = np.zeros(shape = (rings, N_pyramidals))\n",
    "target_virtual_rp = np.zeros(shape = (rings, N_pyramidals))\n",
    "\n",
    "in_range = True\n",
    "\n",
    "for r1 in (x for x in range(N_pa_cells_per_ring) if in_range is True): # Ring 1\n",
    "\n",
    "    for r2 in (y for y in range(N_pa_cells_per_ring) if in_range is True): # Ring 2\n",
    "\n",
    "        for r3 in (z for z in range(N_pa_cells_per_ring) if in_range is True): # Ring 3\n",
    "\n",
    "            source_cell_index = (r1 * N_pa_cells_per_ring ** 2) + (r2 * N_pa_cells_per_ring) + r3 # Steps from 0 to max\n",
    "            \n",
    "            if cell_index != N_pyramidals:\n",
    "\n",
    "                source_cell = input_grid_devices[source_cell_index]\n",
    "                \n",
    "                target_cell_index_r1 = (r1 + 1) * window_size - (window_size // 2) - 1\n",
    "                target_cell_index_r2 = (r2 + 1) * window_size - (window_size // 2) - 1\n",
    "                target_cell_index_r3 = (r3 + 1) * window_size - (window_size // 2) - 1\n",
    "                \n",
    "                target_cell_r1 = exc[0][target_cell_index_r1]\n",
    "                target_cell_r2 = exc[1][target_cell_index_r2]\n",
    "                target_cell_r3 = exc[2][target_cell_index_r3]\n",
    "                \n",
    "                sim.Connect([source_cell], [target_cell_r1], 'all_to_all')#, syn_spec={'weight': w_in_pa, 'delay': delay})\n",
    "                sim.Connect([source_cell], [target_cell_r2], 'all_to_all')#, syn_spec={'weight': w_in_pa, 'delay': delay})\n",
    "                sim.Connect([source_cell], [target_cell_r3], 'all_to_all')#, syn_spec={'weight': w_in_pa, 'delay': delay})\n",
    "\n",
    "                # Gather up data for Pandas, to be used later in grid cell evalutation\n",
    "                \n",
    "                source_cell_indices[source_cell_index] = source_cell_index\n",
    "                source_cells[source_cell_index] = source_cell\n",
    "                target_virtual_rp[0][source_cell_index] = r1\n",
    "                target_virtual_rp[1][source_cell_index] = r2\n",
    "                target_virtual_rp[2][source_cell_index] = r3\n",
    "                target_ring_cells[0][source_cell_index] = target_cell_r1\n",
    "                target_ring_cells[1][source_cell_index] = target_cell_r2\n",
    "                target_ring_cells[2][source_cell_index] = target_cell_r3\n",
    "                target_ring_cell_indices[0][source_cell_index] = target_cell_index_r1\n",
    "                target_ring_cell_indices[1][source_cell_index] = target_cell_index_r2\n",
    "                target_ring_cell_indices[2][source_cell_index] = target_cell_index_r3\n",
    "                \n",
    "#             else:\n",
    "                \n",
    "#                 in_range = False\n",
    "                \n",
    "input_device_to_ring_cells_connections = pd.DataFrame({ 'Source Device Index': source_cell_indices,\n",
    "                                                        'Source Device': source_cells,\n",
    "                                                        'Ring 1 Virtual RP' : target_virtual_rp[0],\n",
    "                                                        'Ring 2 Virtual RP' : target_virtual_rp[1],\n",
    "                                                        'Ring 3 Virtual RP' : target_virtual_rp[2],\n",
    "                                                        'Ring 1 Index': target_ring_cell_indices[0],\n",
    "                                                        'Ring 2 Index': target_ring_cell_indices[1],\n",
    "                                                        'Ring 3 Index': target_ring_cell_indices[2],\n",
    "                                                        'Ring 1 Cell': target_ring_cells[0],\n",
    "                                                        'Ring 2 Cell': target_ring_cells[1],\n",
    "                                                        'Ring 3 Cell': target_ring_cells[2],})\n",
    "\n",
    "print(input_device_to_ring_cells_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846efb6c-d2ec-46d6-8220-549e113c264c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_cell_r3)\n",
    "print(len(sim.GetConnections([target_cell_r3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbbe223-861d-4f94-b894-8ca6241142c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.GetConnections([source_cell])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4421c1c-892e-4ea6-85e3-caadfcaa0c73",
   "metadata": {},
   "source": [
    "## Record spike activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34fcbe1-005e-4b5e-9678-3ee1ef6a30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single spike detectors, connected to all cells in the given population in a given ring\n",
    "# 'params' dictionary describes which variables to log; gid: global neuron id, time is in milliseconds\n",
    "\n",
    "exc_spikes = []\n",
    "inh_spikes = []\n",
    "pa_spikes = []\n",
    "left_cj_spikes = []\n",
    "right_cj_spikes = []\n",
    "\n",
    "for i in range(rings):\n",
    "\n",
    "    exc_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "    sim.Connect(exc[i],exc_spikes[i])\n",
    "    \n",
    "    inh_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "    sim.Connect(inh[i],inh_spikes[i])\n",
    "    \n",
    "    pa_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "    sim.Connect(pa_cells[i],pa_spikes[i])\n",
    "    \n",
    "    left_cj_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "    sim.Connect(l[i],left_cj_spikes[i])\n",
    "    \n",
    "    right_cj_spikes.append(sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True}))\n",
    "    sim.Connect(r[i],right_cj_spikes[i])\n",
    "    \n",
    "pyramidal_spikes = sim.Create(\"spike_detector\", 1, params={\"withgid\": True,\"withtime\": True})\n",
    "sim.Connect(pyramidal_cells,pyramidal_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edeb44f-d751-4d3d-a8fe-c2348e6cd67b",
   "metadata": {},
   "source": [
    "## Record cell voltage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17d8b66d-7b83-49b2-8bde-b133e2aab3f4",
   "metadata": {},
   "source": [
    "# Single spike detectors, connected to all cells in the given population in a given ring\n",
    "# 'params' dictionary describes which variables to log; 'gid': global neuron id, 'time' is in milliseconds\n",
    "# 'interval' is the frequency of logging, in milliseconds\n",
    "# 'record_from' dictionary describes which neuron variables to log; 'V_m': membrane voltage, \n",
    "#                                                                   'weighted_spikes_ex': weighted sum of incoming excitatory spikes,\n",
    "#                                                                   'weighted_spikes_in': weighted sum of incoming inhibitory spikes\n",
    "\n",
    "exc_voltage = []\n",
    "inh_voltage = []\n",
    "pa_voltage = []\n",
    "left_cj_voltage = []\n",
    "right_cj_voltage = []\n",
    "\n",
    "for i in range(rings):\n",
    "\n",
    "    exc_voltage.append(sim.Create(\"multimeter\", 1, params={\"withgid\": True, \"interval\": 20., \"withtime\": True, 'record_from': ['V_m', 'weighted_spikes_ex', 'weighted_spikes_in']}))\n",
    "    sim.Connect(exc_voltage[i],exc[i])\n",
    "    \n",
    "    inh_voltage.append(sim.Create(\"multimeter\", 1, params={\"withgid\": True, \"interval\": 20., \"withtime\": True, 'record_from': ['V_m', 'weighted_spikes_ex', 'weighted_spikes_in']}))\n",
    "    sim.Connect(inh_voltage[i], inh[i])\n",
    "\n",
    "    pa_voltage.append(sim.Create(\"multimeter\", 1, params={\"withgid\": True, \"interval\": 20., \"withtime\": True, 'record_from': ['V_m', 'weighted_spikes_ex', 'weighted_spikes_in']}))\n",
    "    sim.Connect(pa_voltage[i], pa_cells[i])\n",
    "\n",
    "    left_cj_voltage.append(sim.Create(\"multimeter\", 1, params={\"withgid\": True, \"interval\": 20., \"withtime\": True, 'record_from': ['V_m', 'weighted_spikes_ex', 'weighted_spikes_in']}))\n",
    "    sim.Connect(left_cj_voltage[i], l[i])\n",
    "\n",
    "    right_cj_voltage.append(sim.Create(\"multimeter\", 1, params={\"withgid\": True, \"interval\": 20., \"withtime\": True, 'record_from': ['V_m', 'weighted_spikes_ex', 'weighted_spikes_in']}))\n",
    "    sim.Connect(right_cj_voltage[i],r[i])\n",
    "    \n",
    "pyramidal_voltage = sim.Create(\"multimeter\", 1, params={\"withgid\": True, \"interval\": 20., \"withtime\": True, 'record_from': ['V_m', 'weighted_spikes_ex', 'weighted_spikes_in']})\n",
    "sim.Connect(pyramidal_voltage, pyramidal_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd1fe9-e4ba-4b86-b38b-c968b2fda5a5",
   "metadata": {},
   "source": [
    "## Input to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8365b080-e90f-4e3a-8af7-14c3a24f630e",
   "metadata": {},
   "source": [
    "## PredNet representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53c453-54a9-49fb-acb5-088a45c9789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation_root_folder = 'data/NRP_reps/'\n",
    "\n",
    "representation_folders = [ \"playground_ordered_testset1\",\n",
    "                           \"playground_ordered_testset2\",\n",
    "                           \"playground_ordered_testset3\",\n",
    "                           \"playground_ordered_testset4\",\n",
    "                           \"playground_ordered_testset5\",\n",
    "                           \"playground_ordered_testset6\" ]\n",
    "\n",
    "representations = [np.load(representation_root_folder + folder + \"/both/representations.npy\") for folder in representation_folders]\n",
    "\n",
    "print(representations[0].shape)\n",
    "\n",
    "representations_per_dataset = [reps.shape[0] for reps in representations]\n",
    "\n",
    "representations = np.vstack(representations)\n",
    "\n",
    "print(representations.shape)\n",
    "\n",
    "print(representations_per_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8bcfd-df66-4df9-bc2e-d180fd96dca7",
   "metadata": {},
   "source": [
    "### Position data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a52d8-65a2-40a8-92f4-585e25d47f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two options for getting input data for the network. In all cases, position data is loaded/generated, then velocity derived in later cells\n",
    "# 'spiral': original spiral trajectory\n",
    "# 'rat': load one of the Sargolini group's datasets, from real rat foraging task data\n",
    "\n",
    "if spiral_or_rat == 'spiral':\n",
    "    \n",
    "    number_of_turns = 300\n",
    "    numT = number_of_turns * 1000 * np.pi\n",
    "    print(numT/1000)\n",
    "    dt = 20\n",
    "    t = np.arange(0,sim_len,dt)*1.\n",
    "    time = [i * 1. for i in t if i < sim_len]\n",
    "    ts = np.arange(0,numT,numT/len(t))/1000.\n",
    "    V = 30\n",
    "    dr = 5\n",
    "    ph = -np.sqrt(((V * (4*np.pi) * ts) / dr))\n",
    "    ra =  np.sqrt(((V * dr * ts) / np.pi))\n",
    "\n",
    "    pos_x = ra * np.cos(ph) \n",
    "    pos_y = ra * np.sin(ph)\n",
    "    \n",
    "elif spiral_or_rat == 'rat':\n",
    "    \n",
    "    # Roughly 92 20ms timesteps per representation\n",
    "    \n",
    "    N_data_samples = 4000\n",
    "    N_representations = 50\n",
    "    \n",
    "    assert N_representations <= len(representations)\n",
    "    \n",
    "    from scipy.ndimage import median_filter, gaussian_filter\n",
    "    \n",
    "    # Load rat trajectory data from file\n",
    "    \n",
    "    data_folders = ['NRP_2021_testset1', 'NRP_2021_testset2', 'NRP_2021_testset3',\n",
    "                    'NRP_2021_testset4', 'NRP_2021_testset5', 'NRP_2021_testset6']\n",
    "    \n",
    "    #data_folders = ['NRP_2021_testset1', 'NRP_2021_testset2']\n",
    "    \n",
    "    rat_dataset = [np.loadtxt('data/NRP_data/{}/raw_pose.csv'.format(folder), skiprows = 1, delimiter = ',') for folder in data_folders]\n",
    "    \n",
    "    # Find where each dataset ends. Timesteps also reset at these points.\n",
    "    \n",
    "    dataset_ends = [len(testset) for testset in rat_dataset]\n",
    "    \n",
    "    print(f\"Component dataset sizes: {dataset_ends}\")\n",
    "    \n",
    "    # Find where they will end in the combined dataset\n",
    "    \n",
    "    dataset_ends_cumulative = [sum(dataset_ends[:i]) - 1 for i in range(1,len(dataset_ends)+1)]\n",
    "    \n",
    "    # Apply the required fixes as per the README\n",
    "    \n",
    "    # rat_dataset[2][:,1] = rat_dataset[2][:,1] - 3 # Testset 3 needs adjusting -3m X and -6.1 Y\n",
    "    # rat_dataset[2][:,2] = rat_dataset[2][:,2] - 6.1# Testset 3 needs adjusting -3m X and -6.1 Y\n",
    "    # rat_dataset[3][:,2] = rat_dataset[3][:,2] - 6.1# Testset 4 needs adjusting -6.1 Y\n",
    "    \n",
    "    rat_dataset = np.vstack(rat_dataset)\n",
    "    \n",
    "    plt.plot(rat_dataset[:,0])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Find the actual timestamps where each dataset end\n",
    "    \n",
    "    dataset_max_timestamps = rat_dataset[dataset_ends_cumulative, 0]\n",
    "    \n",
    "    # For each window of data, add on the previous maximum value; this should give a combined dataset with a monotonically increasing timestep\n",
    "    \n",
    "    dataset_cumulative_max_timestamps = [sum(dataset_max_timestamps[:i]) for i in range(1,len(dataset_max_timestamps)+1)]\n",
    "    \n",
    "    rat_dataset_timesteps_in_sequence = rat_dataset.copy()\n",
    "    \n",
    "    rat_dataset_timesteps_in_sequence[dataset_ends_cumulative[0]+1:, 0] = np.hstack([rat_dataset[i+1:j+1, 0] + m for i, j, m in zip(dataset_ends_cumulative[:-1], dataset_ends_cumulative[1:], dataset_cumulative_max_timestamps[:-1])])\n",
    "    \n",
    "    plt.plot(rat_dataset_timesteps_in_sequence[:,0])\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    assert np.all(rat_dataset_timesteps_in_sequence[1:, 0] > rat_dataset_timesteps_in_sequence[:-1, 0])\n",
    "    \n",
    "    # Now do the same for the representations\n",
    "    \n",
    "    rat_representation_timestamps = [np.load('data/NRP_data/{}/representation_matched_poses.npy'.format(folder))[:rep_count, 0] for folder, rep_count in zip(data_folders, representations_per_dataset)]\n",
    "    \n",
    "    # Find where each dataset ends. Timesteps also reset at these points.\n",
    "    \n",
    "    dataset_ends = [len(testset) for testset in rat_representation_timestamps]\n",
    "    \n",
    "    print(dataset_ends)\n",
    "    \n",
    "    # Find where they will end in the combined dataset\n",
    "    \n",
    "    dataset_ends_cumulative = [sum(dataset_ends[:i]) - 1 for i in range(1,len(dataset_ends)+1)]\n",
    "    \n",
    "    print(dataset_ends_cumulative)\n",
    "    \n",
    "    rat_representation_timestamps = np.hstack(rat_representation_timestamps)\n",
    "    \n",
    "    plt.plot(rat_representation_timestamps)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    # Find the actual timestamps where each dataset end\n",
    "    \n",
    "    dataset_max_timestamps = rat_representation_timestamps[dataset_ends_cumulative]\n",
    "    \n",
    "    # For each window of data, add on the previous maximum value; this should give a combined dataset with a monotonically increasing timestep\n",
    "    \n",
    "    dataset_cumulative_max_timestamps = [sum(dataset_max_timestamps[:i]) for i in range(1,len(dataset_max_timestamps)+1)]\n",
    "    \n",
    "    rat_representations_timesteps_in_sequence = rat_representation_timestamps.copy()\n",
    "    \n",
    "    rat_representations_timesteps_in_sequence[dataset_ends_cumulative[0]+1:] = np.hstack([rat_representation_timestamps[i+1:j+1] + m for i, j, m in zip(dataset_ends_cumulative[:-1], dataset_ends_cumulative[1:], dataset_cumulative_max_timestamps[:-1])])\n",
    "    \n",
    "    plt.plot(rat_representations_timesteps_in_sequence)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    assert np.all(rat_representations_timesteps_in_sequence[1:] > rat_representations_timesteps_in_sequence[:-1])\n",
    "    \n",
    "    rat_dataset_timesteps_in_sequence = rat_dataset_timesteps_in_sequence[:N_data_samples]\n",
    "    rat_representations_timesteps_in_sequence = rat_representations_timesteps_in_sequence[:N_representations]\n",
    "    \n",
    "    # Now find where injections are required\n",
    "    \n",
    "    plt.scatter(np.linspace(0, max(rat_dataset_timesteps_in_sequence[:, 0]), num = len(rat_dataset_timesteps_in_sequence)), rat_dataset_timesteps_in_sequence[:, 0])\n",
    "    plt.scatter(np.linspace(0, max(rat_dataset_timesteps_in_sequence[:, 0]), num = len(rat_representations_timesteps_in_sequence)), rat_representations_timesteps_in_sequence)\n",
    "    plt.show()\n",
    "    \n",
    "    rat_injection_index = np.searchsorted(rat_dataset_timesteps_in_sequence[:, 0], rat_representations_timesteps_in_sequence)\n",
    "    \n",
    "    # Get rid of any redundant injections (only 2 at last check, so doesn't seem to be a systematic issue)\n",
    "    \n",
    "    rat_injection_index = rat_injection_index[np.nonzero(np.diff(rat_injection_index) > 0)]\n",
    "    \n",
    "    assert np.all(rat_injection_index[1:] > rat_injection_index[:-1])\n",
    "    \n",
    "    # Trim to desired interval\n",
    "    \n",
    "    # print(max(rat_dataset_timesteps_in_sequence[:,0]))\n",
    "    # print(max(rat_representations_timesteps_in_sequence))\n",
    "    # print(max(rat_injection_index))\n",
    "    \n",
    "    # rat_dataset_timesteps_in_sequence = rat_dataset_timesteps_in_sequence[:N_data_samples]\n",
    "    # rat_representations_timesteps_in_sequence = rat_representations_timesteps_in_sequence[:N_representations]\n",
    "#     rat_injection_index = rat_injection_index[rat_injection_index < int(max(rat_representations_timesteps_in_sequence))]\n",
    "    \n",
    "#     print(max(rat_dataset_timesteps_in_sequence[:,0]))\n",
    "#     print(max(rat_representations_timesteps_in_sequence))\n",
    "#     print(max(rat_injection_index))\n",
    "    \n",
    "    \n",
    "    # Create variables for velocity calculation later\n",
    "    \n",
    "    pos_x = rat_dataset_timesteps_in_sequence[:,1]\n",
    "    #pos_x = gaussian_filter(pos_x, sigma = smooth_sigma, mode = 'nearest')\n",
    "    pos_y = rat_dataset_timesteps_in_sequence[:,2]\n",
    "    #pos_y = gaussian_filter(pos_y, sigma = smooth_sigma, mode = 'nearest')\n",
    "    \n",
    "    theta = rat_dataset_timesteps_in_sequence[:,3]\n",
    "    \n",
    "    print(f\"Original count {len(pos_x)}\")\n",
    "    #timestamps = np.arange(0, len(rat_dataset_timesteps_in_sequence)) / 50 # Hz\n",
    "    timestamps = rat_dataset_timesteps_in_sequence[:, 0] - np.min(rat_dataset_timesteps_in_sequence[:, 0])\n",
    "    \n",
    "    timestamps = timestamps / 1000000000 # Get from nanoseconds to seconds\n",
    "\n",
    "    plt.plot(timestamps)\n",
    "    plt.show()\n",
    "    \n",
    "    representation_timestamps = timestamps[rat_injection_index]\n",
    "    \n",
    "    print(f\"Representations: {len(representation_timestamps)}\")\n",
    "    \n",
    "    print(np.diff(timestamps))\n",
    "    print(np.mean(np.diff(timestamps)))\n",
    "    print(np.mean(np.diff(representation_timestamps)))\n",
    "    \n",
    "    time = timestamps * 1000 # Get from seconds to milliseconds\n",
    "    \n",
    "    representation_times = time[rat_injection_index]\n",
    "    \n",
    "    print(f\"Times: {len(time)}\")\n",
    "    \n",
    "    print(max(time))\n",
    "    \n",
    "    print(f\"Representation Times: {len(representation_times)}\")\n",
    "    \n",
    "    print(max(representation_times))\n",
    "    \n",
    "    # assert representation_timestamps[-1] <= timestamps[-1]\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70abdde2-04cb-451b-80fb-09e8066521ce",
   "metadata": {},
   "source": [
    "## Plot the loaded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da0c52-6c86-46ba-ab7a-dca6f3f293d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rat_dataset_timesteps_in_sequence))\n",
    "print(len(rat_representations_timesteps_in_sequence))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (10,8))\n",
    "\n",
    "from matplotlib.colors import Normalize as colour_norm\n",
    "from matplotlib import cm\n",
    "\n",
    "velocity_magnitude = np.sqrt(np.diff(pos_x) ** 2 + np.diff(pos_y) ** 2)\n",
    "colour_index = velocity_magnitude#np.linspace(0, 1, num = 120)\n",
    "velocity_colours = cm.get_cmap('viridis')(colour_index)\n",
    "\n",
    "print(velocity_colours.shape)\n",
    "print(pos_x[:-1].shape)\n",
    "print(pos_y[:-1].shape)\n",
    "\n",
    "ax.scatter(pos_x[:-1],pos_y[:-1], c = velocity_colours, s = 1, alpha = 0.5)\n",
    "ax.scatter(pos_x[0],pos_y[0], c = 'red', s = 200, alpha = 1)\n",
    "\n",
    "norm = colour_norm(vmin=min(velocity_magnitude), vmax=max(velocity_magnitude))\n",
    "\n",
    "norm_colours = norm(velocity_colours)\n",
    "\n",
    "velocity_colours = cm.ScalarMappable(norm = norm, cmap = 'viridis')\n",
    "\n",
    "fig.colorbar(velocity_colours, ax = ax)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8,8))\n",
    "\n",
    "ax.hist(velocity_magnitude, bins = 1000)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (10, 8))\n",
    "\n",
    "ax = fig.add_subplot(1,1,1, projection = '3d')\n",
    "\n",
    "velocity_colours = cm.get_cmap('plasma')(colour_index)\n",
    "\n",
    "ax.scatter(pos_x[:-1], pos_y[:-1], time[:-1], c = velocity_colours, s = 1, alpha = 0.5)\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.set_zlabel(\"Time (ms)\")\n",
    "\n",
    "velocity_colours = cm.ScalarMappable(norm = norm, cmap = 'plasma')\n",
    "\n",
    "fig.colorbar(velocity_colours, ax = ax)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize = (8,8))\n",
    "\n",
    "print(f\"Final count {len(pos_x)}\")\n",
    "\n",
    "ax.quiver(pos_x[::15], pos_y[::15], np.cos(theta)[::15], np.sin(theta)[::15], angles = 'xy', pivot = 'tail')\n",
    "\n",
    "ax.scatter(pos_x[rat_injection_index], pos_y[rat_injection_index], s = 2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "vel_x = np.diff(pos_x)\n",
    "vel_y = np.diff(pos_y)\n",
    "\n",
    "vel_x,vel_y = vel_x*I_vel, vel_y*I_vel\n",
    "\n",
    "velocity_magnitude = np.sqrt(vel_x ** 2 + vel_y ** 2)\n",
    "\n",
    "plt.plot(velocity_magnitude)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "update_time = np.diff(time)\n",
    "\n",
    "plt.hist(update_time)\n",
    "\n",
    "print(np.unique(update_time, return_counts = True))\n",
    "\n",
    "#time = np.arange(0, max(time)+20, step = 20).astype('float')\n",
    "\n",
    "print(len(time))\n",
    "print(len(vel_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb01b4e7-ea71-4d92-811e-70b3169fca40",
   "metadata": {},
   "source": [
    "### Calculate velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9fb75-5dc3-4021-ba71-4853c131972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate velocity to convert to step current\n",
    "# As with head direction network, small values are boosted, but values that were 0 or less are set back to 0\n",
    "\n",
    "vel_x = np.diff(pos_x)\n",
    "vel_y = np.diff(pos_y)\n",
    "\n",
    "if calibration_mode:\n",
    "    \n",
    "    vel_x = np.zeros_like(vel_x)\n",
    "    vel_y = np.zeros_like(vel_y)\n",
    "\n",
    "vel_x,vel_y = vel_x*I_vel, vel_y*I_vel\n",
    "\n",
    "# Now we split this across the rings according to their direction of travel\n",
    "\n",
    "# Axes are:\n",
    "# Y, as usual\n",
    "# X_plus_60 (60 degree offset from Y around origin, diagonal bottom-right to upper-left)\n",
    "# X_plus_120 (120 degree offset from Y around origin, diagonal bottom-left to upper-right)\n",
    "\n",
    "velocity_magnitude = np.sqrt(vel_x ** 2 + vel_y ** 2)\n",
    "\n",
    "#if velocity_threshold:\n",
    "\n",
    "#    velocity_magnitude = velocity_magnitude + minimum_velocity\n",
    "\n",
    "#    velocity_magnitude[velocity_magnitude < minimum_velocity] = 0.\n",
    "\n",
    "velocity_angle = np.arctan2(vel_y, vel_x)\n",
    "\n",
    "# Calculate overall components for use in later analysis\n",
    "\n",
    "Y_input_total = velocity_magnitude * np.cos(velocity_angle)\n",
    "\n",
    "Y_plus_60_offset = np.radians(60)\n",
    "Y_plus_120_offset = np.radians(120)\n",
    "\n",
    "Y_plus_60_input_total = velocity_magnitude * np.cos(velocity_angle - Y_plus_60_offset)\n",
    "Y_plus_120_input_total = velocity_magnitude * np.cos(velocity_angle - Y_plus_120_offset)\n",
    "\n",
    "# Now split into positive and negative to feed to left and right conjunctive cells respectively\n",
    "\n",
    "velocity_component = np.cos(velocity_angle)\n",
    "\n",
    "positive_component = velocity_component.copy()\n",
    "negative_component = velocity_component.copy()\n",
    "\n",
    "positive_component[positive_component < 0] = 0.\n",
    "negative_component[negative_component > 0] = 0.\n",
    "\n",
    "Y_input_l = velocity_magnitude * positive_component\n",
    "Y_input_r = velocity_magnitude * negative_component\n",
    "\n",
    "Y_input_r = -Y_input_r\n",
    "\n",
    "Y_input_l_compliment = velocity_magnitude - Y_input_l\n",
    "Y_input_r_compliment = velocity_magnitude - Y_input_r\n",
    "\n",
    "Y_input_l = velocity_magnitude + Y_input_l + Y_input_r_compliment + minimum_input\n",
    "Y_input_r = velocity_magnitude + Y_input_r + Y_input_l_compliment + minimum_input\n",
    "    \n",
    "# Connect y input to conjunctive layers\n",
    "\n",
    "print(len(time[1:]))\n",
    "print(len(Y_input_l))\n",
    "\n",
    "y_l_input = sim.Create('step_current_generator', 1)\n",
    "sim.SetStatus(y_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_input_l})\n",
    "\n",
    "y_r_input = sim.Create('step_current_generator', 1)\n",
    "sim.SetStatus(y_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_input_r})\n",
    "\n",
    "sim.Connect(y_l_input,l[0],'all_to_all')\n",
    "sim.Connect(y_r_input,r[0],'all_to_all')\n",
    "\n",
    "\n",
    "velocity_component_60 = np.cos(velocity_angle - Y_plus_60_offset)\n",
    "\n",
    "positive_component_60 = velocity_component_60.copy()\n",
    "negative_component_60 = velocity_component_60.copy()\n",
    "\n",
    "positive_component_60[positive_component_60 < 0] = 0.\n",
    "negative_component_60[negative_component_60 > 0] = 0.\n",
    "\n",
    "Y_plus_60_input_l = velocity_magnitude * positive_component_60 # np.cos(positive_angle - Y_plus_60_offset)\n",
    "Y_plus_60_input_r = velocity_magnitude * negative_component_60 # np.cos(negative_angle - Y_plus_60_offset)\n",
    "\n",
    "Y_plus_60_input_r = -Y_plus_60_input_r\n",
    "\n",
    "Y_plus_60_input_l_compliment = velocity_magnitude - Y_plus_60_input_l\n",
    "Y_plus_60_input_r_compliment = velocity_magnitude - Y_plus_60_input_r\n",
    "\n",
    "Y_plus_60_input_l = velocity_magnitude + Y_plus_60_input_l + Y_plus_60_input_r_compliment + minimum_input\n",
    "Y_plus_60_input_r = velocity_magnitude + Y_plus_60_input_r + Y_plus_60_input_l_compliment + minimum_input\n",
    "\n",
    "\n",
    "velocity_component_120 = np.cos(velocity_angle - Y_plus_120_offset)\n",
    "\n",
    "positive_component_120 = velocity_component_120.copy()\n",
    "negative_component_120 = velocity_component_120.copy()\n",
    "\n",
    "positive_component_120[positive_component_120 < 0] = 0.\n",
    "negative_component_120[negative_component_120 > 0] = 0.\n",
    "\n",
    "Y_plus_120_input_l = velocity_magnitude * positive_component_120 # np.cos(positive_angle - Y_plus_120_offset)\n",
    "Y_plus_120_input_r = velocity_magnitude * negative_component_120 # np.cos(negative_angle - Y_plus_120_offset)\n",
    "\n",
    "Y_plus_120_input_r = -Y_plus_120_input_r\n",
    "                      \n",
    "Y_plus_120_input_l_compliment = velocity_magnitude - Y_plus_120_input_l\n",
    "Y_plus_120_input_r_compliment = velocity_magnitude - Y_plus_120_input_r\n",
    "\n",
    "Y_plus_120_input_l = velocity_magnitude + Y_plus_120_input_l + Y_plus_120_input_r_compliment + minimum_input\n",
    "Y_plus_120_input_r = velocity_magnitude + Y_plus_120_input_r + Y_plus_120_input_l_compliment + minimum_input\n",
    "\n",
    "    \n",
    "# Connect y_plus_60 input to conjunctive layers\n",
    "\n",
    "Y_plus_60_l_input = sim.Create('step_current_generator', 1)\n",
    "sim.SetStatus(Y_plus_60_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_60_input_l})\n",
    "Y_plus_60_r_input = sim.Create('step_current_generator', 1)\n",
    "sim.SetStatus(Y_plus_60_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_60_input_r})\n",
    "\n",
    "sim.Connect(Y_plus_60_l_input,l[1],'all_to_all')\n",
    "sim.Connect(Y_plus_60_r_input,r[1],'all_to_all')\n",
    "\n",
    "# Connect y_plus_120 input to conjunctive layers\n",
    "\n",
    "Y_plus_120_l_input = sim.Create('step_current_generator', 1)\n",
    "sim.SetStatus(Y_plus_120_l_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_120_input_l})\n",
    "Y_plus_120_r_input = sim.Create('step_current_generator', 1)\n",
    "sim.SetStatus(Y_plus_120_r_input,{'amplitude_times': time[1:],'amplitude_values': Y_plus_120_input_r})\n",
    "\n",
    "sim.Connect(Y_plus_120_l_input,l[2],'all_to_all')\n",
    "sim.Connect(Y_plus_120_r_input,r[2],'all_to_all')\n",
    "\n",
    "print(min(Y_input_l))\n",
    "print(min(Y_input_r))\n",
    "print(min(Y_plus_60_input_l))\n",
    "print(min(Y_plus_60_input_r))\n",
    "print(min(Y_plus_120_input_l))\n",
    "print(min(Y_plus_120_input_r))\n",
    "\n",
    "\n",
    "# Plot velocity components for sanity's sake\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(25,24), sharey = True)\n",
    "\n",
    "axes[0].scatter(time[:-1], Y_input_l, alpha = 0.7, c = 'lime')\n",
    "axes[0].scatter(time[:-1], Y_input_r, alpha = 0.7, c = 'red')\n",
    "\n",
    "axes[1].scatter(time[:-1], Y_plus_60_input_l, alpha = 0.7, c = 'lime')\n",
    "axes[1].scatter(time[:-1], Y_plus_60_input_r, alpha = 0.7, c = 'red')\n",
    "\n",
    "axes[2].scatter(time[:-1], Y_plus_120_input_l, alpha = 0.7, c = 'lime')\n",
    "axes[2].scatter(time[:-1], Y_plus_120_input_r, alpha = 0.7, c = 'red')\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(25,24), sharey = True)\n",
    "\n",
    "axes[0].scatter(time[:-1], velocity_magnitude * 2, alpha = 0.7, c = 'black')\n",
    "axes[0].scatter(time[:-1], Y_input_l-minimum_input, alpha = 0.7, c = 'lime')\n",
    "axes[0].scatter(time[:-1], -(Y_input_r-minimum_input), alpha = 0.7, c = 'red')\n",
    "\n",
    "axes[1].scatter(time[:-1], velocity_magnitude * 2, alpha = 0.7, c = 'black')\n",
    "axes[1].scatter(time[:-1], Y_plus_60_input_l-minimum_input, alpha = 0.7, c = 'lime')\n",
    "axes[1].scatter(time[:-1], -(Y_plus_60_input_r-minimum_input), alpha = 0.7, c = 'red')\n",
    "\n",
    "axes[2].scatter(time[:-1], velocity_magnitude * 2, alpha = 0.7, c = 'black')\n",
    "axes[2].scatter(time[:-1], Y_plus_120_input_l-minimum_input, alpha = 0.7, c = 'lime')\n",
    "axes[2].scatter(time[:-1], -(Y_plus_120_input_r-minimum_input), alpha = 0.7, c = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc326a5c-50bc-4f24-bb4b-b1a91d960ee6",
   "metadata": {},
   "source": [
    "### Bump-forming current generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85512aee-984d-4952-9fa2-876f003ae7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject current for a given duration to start the bump off\n",
    "\n",
    "bump_init = sim.Create('step_current_generator', 1, params = {'amplitude_times':[0.1,0.1+I_init_dur],'amplitude_values':[I_init,0.0]})\n",
    "sim.Connect(bump_init,[exc[0][I_init_pos]])\n",
    "sim.Connect(bump_init,[exc[1][I_init_pos]])\n",
    "sim.Connect(bump_init,[exc[2][I_init_pos]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e80ff-92ea-4b28-be23-93f5d232c02e",
   "metadata": {},
   "source": [
    "### Additional bump-forming generators to check corrective influence (delete later)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7500857c-39d4-4d6a-8fd0-7a4a6794ae0b",
   "metadata": {},
   "source": [
    "bump_init_2 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*1.25, I_init*2.5, I_init*1.25, 0.0]})\n",
    "sim.Connect(bump_init_2,[exc[0][I_init_pos+window_size//2]])\n",
    "sim.Connect(bump_init_2,[exc[1][I_init_pos+window_size//2]])\n",
    "sim.Connect(bump_init_2,[exc[2][I_init_pos+window_size//2]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fad6ea94-cc7e-4a52-adf0-84e6d16ac65b",
   "metadata": {},
   "source": [
    "bump_init_gauss_1 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*0.5, I_init*1, I_init*0.5, 0.0]})\n",
    "bump_init_gauss_2 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*1.0, I_init*2, I_init*1.0, 0.0]})\n",
    "bump_init_gauss_3 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*0.5, I_init*1, I_init*0.5, 0.0]})\n",
    "\n",
    "sim.Connect(bump_init_gauss_1,[exc[0][I_init_pos+(window_size//2)-1]])\n",
    "sim.Connect(bump_init_gauss_2,[exc[0][I_init_pos+window_size//2]])\n",
    "sim.Connect(bump_init_gauss_3,[exc[0][I_init_pos+(window_size//2)+1]])\n",
    "\n",
    "sim.Connect(bump_init_gauss_1,[exc[1][I_init_pos+(window_size//2)-1]])\n",
    "sim.Connect(bump_init_gauss_2,[exc[1][I_init_pos+window_size//2]])\n",
    "sim.Connect(bump_init_gauss_3,[exc[1][I_init_pos+(window_size//2)+1]])\n",
    "\n",
    "sim.Connect(bump_init_gauss_1,[exc[2][I_init_pos+(window_size//2)-1]])\n",
    "sim.Connect(bump_init_gauss_2,[exc[2][I_init_pos+window_size//2]])\n",
    "sim.Connect(bump_init_gauss_3,[exc[2][I_init_pos+(window_size//2)+1]])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ed509a4-7de8-4283-ba7c-95c953cbcfb0",
   "metadata": {},
   "source": [
    "bump_init_gauss_1 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*0.25, I_init*0.5, I_init*0.25, 0.0]})\n",
    "bump_init_gauss_2 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*0.5, I_init*1.0, I_init*0.5, 0.0]})\n",
    "bump_init_gauss_3 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*1.0, I_init*2.0, I_init*1.0, 0.0]})\n",
    "bump_init_gauss_4 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*0.5, I_init*1, I_init*0.25, 0.0]})\n",
    "bump_init_gauss_5 = sim.Create('step_current_generator', 1, params = {'amplitude_times':[2000.,2500.,3000., 3500.],'amplitude_values':[I_init*0.25, I_init*0.5, I_init*0.25, 0.0]})\n",
    "\n",
    "sim.Connect(bump_init_gauss_1,[exc[0][I_init_pos+(window_size//2)-2]])\n",
    "sim.Connect(bump_init_gauss_2,[exc[0][I_init_pos+(window_size//2)-1]])\n",
    "sim.Connect(bump_init_gauss_3,[exc[0][I_init_pos+(window_size//2)+0]])\n",
    "sim.Connect(bump_init_gauss_4,[exc[0][I_init_pos+(window_size//2)+1]])\n",
    "sim.Connect(bump_init_gauss_5,[exc[0][I_init_pos+(window_size//2)+2]])\n",
    "\n",
    "sim.Connect(bump_init_gauss_1,[exc[1][I_init_pos+(window_size//2)-2]])\n",
    "sim.Connect(bump_init_gauss_2,[exc[1][I_init_pos+(window_size//2)-1]])\n",
    "sim.Connect(bump_init_gauss_3,[exc[1][I_init_pos+(window_size//2)+0]])\n",
    "sim.Connect(bump_init_gauss_4,[exc[1][I_init_pos+(window_size//2)+1]])\n",
    "sim.Connect(bump_init_gauss_5,[exc[1][I_init_pos+(window_size//2)+2]])\n",
    "\n",
    "sim.Connect(bump_init_gauss_1,[exc[2][I_init_pos+(window_size//2)-2]])\n",
    "sim.Connect(bump_init_gauss_2,[exc[2][I_init_pos+(window_size//2)-1]])\n",
    "sim.Connect(bump_init_gauss_3,[exc[2][I_init_pos+(window_size//2)+0]])\n",
    "sim.Connect(bump_init_gauss_4,[exc[2][I_init_pos+(window_size//2)+1]])\n",
    "sim.Connect(bump_init_gauss_5,[exc[2][I_init_pos+(window_size//2)+2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625d34fc-85fd-4e68-810c-e3650c85387d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pa_to_pyramidal_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b32cb-6c4c-4038-8216-97ef38d35889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_device_to_ring_cells_connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998164e4-f2e1-4372-b2be-05b8bdb06764",
   "metadata": {},
   "source": [
    "## Run simulation in tandem with representation corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be89a436-6860-4eed-9377-cddbe2de2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the memory set up and data loaded\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "sense_memories = [] # Save representations from PredNet\n",
    "location_memories = [] # Save ring coordinates from NEST\n",
    "\n",
    "recall_threshold = 0.8\n",
    "\n",
    "history_timestep_window = 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3bcf9134-adae-4ae4-84cf-626efc9a65db",
   "metadata": {},
   "source": [
    "# Run simulation in small steps, injecting when required\n",
    "\n",
    "time_deltas = np.diff(time).astype(int)\n",
    "\n",
    "start_delay = 100\n",
    "\n",
    "no_spike_timeout = 5\n",
    "\n",
    "recalls = 0\n",
    "new_memories = 0\n",
    "\n",
    "sim.set_verbosity(18)\n",
    "\n",
    "correction_duration = 500.\n",
    "correction_current = 450. # 450 is the sweet spot to apply corrections without wild spinning of the bump\n",
    "\n",
    "injection_type = \"mono\"\n",
    "\n",
    "current_exc_state = np.zeros(shape = (rings, N_ex))\n",
    "exc_state_history = np.zeros(shape = (len(timestamps), rings, N_ex))\n",
    "\n",
    "current_rp_state = np.zeros(shape = (rings, N_pa_cells_per_ring))\n",
    "\n",
    "injection_state_history = np.zeros_like(exc_state_history)\n",
    "\n",
    "representation_index = 0\n",
    "\n",
    "if simulate_or_load == 'simulate':    \n",
    "    \n",
    "    with sim.RunManager():\n",
    "    \n",
    "        for time_delta, t, tick in zip(time_deltas, time, range(len(time))):\n",
    "        \n",
    "            sim.Run(time_delta)\n",
    "            \n",
    "            ring1_exc, ring1_spikes_exc = np.unique(sim.GetStatus(exc_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "            ring2_exc, ring2_spikes_exc = np.unique(sim.GetStatus(exc_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "            ring3_exc, ring3_spikes_exc = np.unique(sim.GetStatus(exc_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "            \n",
    "            current_exc_state[0, ring1_exc-min(exc[0])] = ring1_spikes_exc if ring1_spikes_exc.size > 0 else 0\n",
    "            current_exc_state[1, ring2_exc-min(exc[1])] = ring2_spikes_exc if ring2_spikes_exc.size > 0 else 0\n",
    "            current_exc_state[2, ring3_exc-min(exc[2])] = ring3_spikes_exc if ring3_spikes_exc.size > 0 else 0\n",
    "            \n",
    "            # ring1_most_active_exc_index = np.argmax(ring1_spikes_exc) if ring1_spikes_exc.size > 0 else None\n",
    "            # ring2_most_active_exc_index = np.argmax(ring2_spikes_exc) if ring2_spikes_exc.size > 0 else None\n",
    "            # ring3_most_active_exc_index = np.argmax(ring3_spikes_exc) if ring3_spikes_exc.size > 0 else None\n",
    "            \n",
    "            #current_exc_state = (ring1_most_active_exc_index, ring2_most_active_exc_index, ring3_most_active_exc_index)\n",
    "            \n",
    "            ring1_most_active_exc_index = np.argmax(current_exc_state[0, :]) if np.argmax(current_exc_state[0, :]) is not None else None\n",
    "            ring2_most_active_exc_index = np.argmax(current_exc_state[1, :]) if np.argmax(current_exc_state[1, :]) is not None else None\n",
    "            ring3_most_active_exc_index = np.argmax(current_exc_state[2, :]) if np.argmax(current_exc_state[2, :]) is not None else None\n",
    "\n",
    "            current_most_active_exc = (ring1_most_active_exc_index, ring2_most_active_exc_index, ring3_most_active_exc_index)\n",
    "            \n",
    "            if np.all(None not in current_most_active_exc) and t > start_delay:\n",
    "            \n",
    "                exc_state_history[tick, 0, ring1_exc-min(exc[0])] = ring1_spikes_exc\n",
    "                exc_state_history[tick, 1, ring2_exc-min(exc[1])] = ring2_spikes_exc\n",
    "                exc_state_history[tick, 2, ring3_exc-min(exc[2])] = ring3_spikes_exc\n",
    "            \n",
    "            ring1_rp, ring1_spikes_rp = np.unique(sim.GetStatus(pa_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "            ring2_rp, ring2_spikes_rp = np.unique(sim.GetStatus(pa_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "            ring3_rp, ring3_spikes_rp = np.unique(sim.GetStatus(pa_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "            \n",
    "            # ring1_most_active_rp_index = np.argmax(ring1_spikes_rp) if ring1_spikes_rp.size > 0 else None\n",
    "            # ring2_most_active_rp_index = np.argmax(ring2_spikes_rp) if ring2_spikes_rp.size > 0 else None\n",
    "            # ring3_most_active_rp_index = np.argmax(ring3_spikes_rp) if ring3_spikes_rp.size > 0 else None\n",
    "            \n",
    "#             ring1_most_active_rp = ring1_rp[ring1_most_active_rp_index] if ring1_most_active_rp_index is not None else None\n",
    "#             ring2_most_active_rp = ring2_rp[ring2_most_active_rp_index] if ring2_most_active_rp_index is not None else None\n",
    "#             ring3_most_active_rp = ring3_rp[ring3_most_active_rp_index] if ring3_most_active_rp_index is not None else None\n",
    "            \n",
    "#             current_rp_state = (ring1_most_active_rp_index, ring2_most_active_rp_index, ring3_most_active_rp_index)\n",
    "\n",
    "            current_rp_state[0, ring1_rp-min(pa_cells[0])] = ring1_spikes_rp if ring1_spikes_rp.size > 0 else 0\n",
    "            current_rp_state[1, ring2_rp-min(pa_cells[1])] = ring2_spikes_rp if ring2_spikes_rp.size > 0 else 0\n",
    "            current_rp_state[2, ring3_rp-min(pa_cells[2])] = ring3_spikes_rp if ring3_spikes_rp.size > 0 else 0\n",
    "            \n",
    "            ring1_most_active_rp_index = np.argmax(current_rp_state[0, :]) if np.argmax(current_rp_state[0, :]) is not None else None\n",
    "            ring2_most_active_rp_index = np.argmax(current_rp_state[1, :]) if np.argmax(current_rp_state[1, :]) is not None else None\n",
    "            ring3_most_active_rp_index = np.argmax(current_rp_state[2, :]) if np.argmax(current_rp_state[2, :]) is not None else None\n",
    "            \n",
    "            current_most_active_rp = (ring1_most_active_rp_index, ring2_most_active_rp_index, ring3_most_active_rp_index)\n",
    "            \n",
    "#             ring1_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 1 Index\"] == ring1_most_active_rp_index][\"Source Device\"]\n",
    "#             ring2_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 2 Index\"] == ring2_most_active_rp_index][\"Source Device\"]\n",
    "#             ring3_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 3 Index\"] == ring3_most_active_rp_index][\"Source Device\"]\n",
    "            \n",
    "#             current_injection_devices = (ring1_injection_device, ring2_injection_device, ring3_injection_device)\n",
    "\n",
    "            recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = -1, -1, -1\n",
    "    \n",
    "            # Reset spike detectors so that per-time-delta spike counts are recorded only\n",
    "            \n",
    "            if tick % history_timestep_window == 0:\n",
    "            \n",
    "                sim.SetStatus(exc_spikes[0], {'n_events': 0})\n",
    "                sim.SetStatus(exc_spikes[1], {'n_events': 0})\n",
    "                sim.SetStatus(exc_spikes[2], {'n_events': 0})\n",
    "            \n",
    "            if corrections == True and np.all(None not in current_most_active_rp) and t == representation_times[representation_index]:\n",
    "            \n",
    "                if len(sense_memories) == 0:\n",
    "\n",
    "                    sense_memories.append(representations[representation_index])\n",
    "\n",
    "                if len(location_memories) == 0:\n",
    "\n",
    "                    #location_memories.append(current_most_active_rp)\n",
    "                    location_memories.append((0,0,0))\n",
    "\n",
    "                pearson_coorelation = np.empty(shape = (len(sense_memories)))\n",
    "\n",
    "                for sm, sense_memory in enumerate(sense_memories):\n",
    "\n",
    "                    pearson_coorelation[sm] = 1 - pearsonr(representations[representation_index], sense_memory)[0]\n",
    "\n",
    "                best_match_index = np.argmax(pearson_coorelation) if pearson_coorelation.size > 0 else None\n",
    "\n",
    "                best_match_element = sense_memories[best_match_index] if best_match_index is not None else None\n",
    "\n",
    "                best_match_value = pearson_coorelation[best_match_index] if best_match_index is not None else None\n",
    "                \n",
    "\n",
    "                if best_match_value is None and timestamp > start_delay:\n",
    "\n",
    "                    no_spike_timeout -= 1\n",
    "                    \n",
    "\n",
    "                elif best_match_value >= recall_threshold:\n",
    "\n",
    "                    recalls += 1\n",
    "                    \n",
    "                    recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = location_memories[best_match_index]\n",
    "                    \n",
    "                    # recalled_ring_state_r1 += 1\n",
    "                    # recalled_ring_state_r2 += 1\n",
    "                    # recalled_ring_state_r3 += 1\n",
    "                    \n",
    "#                     ring1_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 1 Index\"] == recalled_ring_state_r1][\"Source Device\"]\n",
    "#                     ring2_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 2 Index\"] == recalled_ring_state_r2][\"Source Device\"]\n",
    "#                     ring3_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 3 Index\"] == recalled_ring_state_r3][\"Source Device\"]\n",
    "                    \n",
    "                    #try:\n",
    "                    \n",
    "                    input_device = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Source Device'].values[0])\n",
    "\n",
    "                    #except:\n",
    "                    \n",
    "                        #print(f\"Query unsuccessful; likely corrective input targets do not exist on ring. Corrective input targets 1,2,3: {recalled_ring_state_r1},{recalled_ring_state_r2},{recalled_ring_state_r3}\")\n",
    "                    \n",
    "                    if injection_type == 'mono':\n",
    "                    \n",
    "                        sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                    \n",
    "                        print(f\"Latest exc spike time: {sim.GetStatus(exc_spikes[0])[0]['events']['times'][-1]}\")\n",
    "                        \n",
    "                        target_exc_cell_r1 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 1 Index'].values[0])\n",
    "                        target_exc_cell_r2 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 2 Index'].values[0])\n",
    "                        target_exc_cell_r3 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 3 Index'].values[0])\n",
    "\n",
    "                    \n",
    "                        print(f\"Injecting with device {input_device} targetting RPs: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)} at time {t}, timestep: {tick} until {t+correction_duration}\")\n",
    "                    \n",
    "                        injection_state_history[tick:tick+int(correction_duration // 20), 0, target_exc_cell_r1] = 1\n",
    "                        injection_state_history[tick:tick+int(correction_duration // 20), 1, target_exc_cell_r2] = 1\n",
    "                        injection_state_history[tick:tick+int(correction_duration // 20), 2, target_exc_cell_r3] = 1\n",
    "                    \n",
    "                    elif injection_type == 'gaussian':\n",
    "                        \n",
    "                        left_device = input_device - 1\n",
    "                        right_device = input_device + 1\n",
    "                        \n",
    "                        if left_device not in input_grid_devices:\n",
    "                            \n",
    "                            left_device = input_grid_devices[-1]\n",
    "                            \n",
    "                        if right_device not in input_grid_devices:\n",
    "                            \n",
    "                            right_device = input_grid_devices[0]\n",
    "                        \n",
    "                        sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                        sim.SetStatus([left_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                        sim.SetStatus([right_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                        \n",
    "                elif best_match_value < recall_threshold:\n",
    "\n",
    "                    new_memories += 1\n",
    "\n",
    "                    sense_memories.append(representations[representation_index])\n",
    "\n",
    "                    location_memories.append(current_most_active_rp)\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    print(\"Help\")\n",
    "\n",
    "                \n",
    "                if no_spike_timeout <= 0:\n",
    "\n",
    "                    print(f\"No spikes have been recorded for {no_spike_timeout} input cycles, stopping...\")\n",
    "\n",
    "                    break\n",
    "                    \n",
    "                if representation_index < (len(representation_times) - 1):\n",
    "                    \n",
    "                    representation_index += 1\n",
    "                \n",
    "            print(f\"Timestep: {tick+1}/{len(time_deltas)}; Sim Time: {int(t)}; Ring State: {current_most_active_exc}; RP State: {current_most_active_rp}; Injection Sites: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)}; Memories Stored: {new_memories}; Recall events: {recalls}\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b48c6-b1fc-4116-9314-a970e12a8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_device_to_ring_cells_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3e839-e7f5-4e53-aace-73a16cfb9c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation in small steps, injecting when required\n",
    "\n",
    "# From the docs: Calling SetStatus() inside a RunManager() context or between Prepare() and Cleanup() will lead to unpredictable results.\n",
    "\n",
    "time_deltas = np.diff(time).astype(int)\n",
    "\n",
    "start_delay = 100\n",
    "\n",
    "no_spike_timeout = 5\n",
    "\n",
    "recalls = 0\n",
    "new_memories = 0\n",
    "\n",
    "sim.set_verbosity(18)\n",
    "\n",
    "correction_duration = 500. # 500.\n",
    "correction_current = 450. # 450 is the sweet spot to apply corrections without wild spinning of the bump\n",
    "confidence_scaling = True # Multiply correction_current by Pearson correlation\n",
    "\n",
    "injection_type = \"mono\"\n",
    "\n",
    "current_exc_state = np.zeros(shape = (rings, N_ex))\n",
    "exc_state_history = np.zeros(shape = (len(timestamps), rings, N_ex))\n",
    "\n",
    "current_rp_state = np.zeros(shape = (rings, N_pa_cells_per_ring))\n",
    "\n",
    "injection_state_history = np.zeros_like(exc_state_history)\n",
    "\n",
    "representation_index = 0\n",
    "\n",
    "input_device = None\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "    \n",
    "    for time_delta, t, tick in zip(time_deltas, time, range(len(time))):\n",
    "        \n",
    "        if input_device is not None and corrections == True and np.all(None not in current_most_active_rp) and t == representation_times[representation_index]:\n",
    "\n",
    "            if injection_type == 'mono':\n",
    "\n",
    "                #print(f\"Input device: {input_device}\")\n",
    "                \n",
    "                sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "\n",
    "            elif injection_type == 'gaussian':\n",
    "\n",
    "                left_device = input_device - 1\n",
    "                right_device = input_device + 1\n",
    "\n",
    "                if left_device not in input_grid_devices:\n",
    "\n",
    "                    left_device = input_grid_devices[-1]\n",
    "\n",
    "                if right_device not in input_grid_devices:\n",
    "\n",
    "                    right_device = input_grid_devices[0]\n",
    "                \n",
    "                if confidence_scalingnfidence_scaling:\n",
    "                \n",
    "                    sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                    sim.SetStatus([left_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                    sim.SetStatus([right_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current, 0.0]})\n",
    "                    \n",
    "                elif confidence_scaling and best_match_value is not None:\n",
    "                    \n",
    "                    sim.SetStatus([input_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "                    sim.SetStatus([left_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "                    sim.SetStatus([right_device], {'amplitude_times': [t, t+correction_duration],'amplitude_values': [correction_current * best_match_value, 0.0]})\n",
    "                    \n",
    "                    best_match_value == None\n",
    "                    \n",
    "                input_device == None\n",
    "    \n",
    "        sim.Prepare()\n",
    "        \n",
    "        sim.Run(time_delta)\n",
    "\n",
    "        ring1_exc, ring1_spikes_exc = np.unique(sim.GetStatus(exc_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "        ring2_exc, ring2_spikes_exc = np.unique(sim.GetStatus(exc_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "        ring3_exc, ring3_spikes_exc = np.unique(sim.GetStatus(exc_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "\n",
    "        current_exc_state[0, ring1_exc-min(exc[0])] = ring1_spikes_exc if ring1_spikes_exc.size > 0 else 0\n",
    "        current_exc_state[1, ring2_exc-min(exc[1])] = ring2_spikes_exc if ring2_spikes_exc.size > 0 else 0\n",
    "        current_exc_state[2, ring3_exc-min(exc[2])] = ring3_spikes_exc if ring3_spikes_exc.size > 0 else 0\n",
    "\n",
    "        ring1_most_active_exc_index = np.argmax(current_exc_state[0, :]) if np.argmax(current_exc_state[0, :]) is not None else None\n",
    "        ring2_most_active_exc_index = np.argmax(current_exc_state[1, :]) if np.argmax(current_exc_state[1, :]) is not None else None\n",
    "        ring3_most_active_exc_index = np.argmax(current_exc_state[2, :]) if np.argmax(current_exc_state[2, :]) is not None else None\n",
    "\n",
    "        current_most_active_exc = (ring1_most_active_exc_index, ring2_most_active_exc_index, ring3_most_active_exc_index)\n",
    "\n",
    "        if np.all(None not in current_most_active_exc) and t > start_delay:\n",
    "\n",
    "            exc_state_history[tick, 0, ring1_exc-min(exc[0])] = ring1_spikes_exc\n",
    "            exc_state_history[tick, 1, ring2_exc-min(exc[1])] = ring2_spikes_exc\n",
    "            exc_state_history[tick, 2, ring3_exc-min(exc[2])] = ring3_spikes_exc\n",
    "\n",
    "        ring1_rp, ring1_spikes_rp = np.unique(sim.GetStatus(pa_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "        ring2_rp, ring2_spikes_rp = np.unique(sim.GetStatus(pa_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "        ring3_rp, ring3_spikes_rp = np.unique(sim.GetStatus(pa_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "\n",
    "        current_rp_state[0, ring1_rp-min(pa_cells[0])] = ring1_spikes_rp if ring1_spikes_rp.size > 0 else 0\n",
    "        current_rp_state[1, ring2_rp-min(pa_cells[1])] = ring2_spikes_rp if ring2_spikes_rp.size > 0 else 0\n",
    "        current_rp_state[2, ring3_rp-min(pa_cells[2])] = ring3_spikes_rp if ring3_spikes_rp.size > 0 else 0\n",
    "\n",
    "        ring1_most_active_rp_index = np.argmax(current_rp_state[0, :]) if np.argmax(current_rp_state[0, :]) is not None else None\n",
    "        ring2_most_active_rp_index = np.argmax(current_rp_state[1, :]) if np.argmax(current_rp_state[1, :]) is not None else None\n",
    "        ring3_most_active_rp_index = np.argmax(current_rp_state[2, :]) if np.argmax(current_rp_state[2, :]) is not None else None\n",
    "\n",
    "        current_most_active_rp = (ring1_most_active_rp_index, ring2_most_active_rp_index, ring3_most_active_rp_index)\n",
    "\n",
    "        recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = -1, -1, -1\n",
    "    \n",
    "        sim.Cleanup()\n",
    "    \n",
    "        # Reset spike detectors so that per-time-delta spike counts are recorded only\n",
    "\n",
    "        if tick % history_timestep_window == 0:\n",
    "\n",
    "            sim.SetStatus(exc_spikes[0], {'n_events': 0})\n",
    "            sim.SetStatus(exc_spikes[1], {'n_events': 0})\n",
    "            sim.SetStatus(exc_spikes[2], {'n_events': 0})\n",
    "\n",
    "        if corrections == True and np.all(None not in current_most_active_rp) and t == representation_times[representation_index]:\n",
    "\n",
    "            if len(sense_memories) == 0:\n",
    "\n",
    "                sense_memories.append(representations[representation_index])\n",
    "\n",
    "            if len(location_memories) == 0:\n",
    "\n",
    "                location_memories.append(current_most_active_rp)\n",
    "                #location_memories.append((0,0,0))\n",
    "\n",
    "            pearson_coorelation = np.empty(shape = (len(sense_memories)))\n",
    "\n",
    "            for sm, sense_memory in enumerate(sense_memories):\n",
    "\n",
    "                pearson_coorelation[sm] = pearsonr(representations[representation_index], sense_memory)[0]\n",
    "\n",
    "            best_match_index = np.argmax(pearson_coorelation) if pearson_coorelation.size > 0 else None\n",
    "\n",
    "            best_match_element = sense_memories[best_match_index] if best_match_index is not None else None\n",
    "\n",
    "            best_match_value = pearson_coorelation[best_match_index] if best_match_index is not None else None\n",
    "\n",
    "\n",
    "            if best_match_value is None and timestamp > start_delay:\n",
    "\n",
    "                no_spike_timeout -= 1\n",
    "\n",
    "\n",
    "            elif best_match_value >= recall_threshold:\n",
    "\n",
    "                recalls += 1\n",
    "\n",
    "                recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = location_memories[best_match_index]\n",
    "\n",
    "                # recalled_ring_state_r1 += 1\n",
    "                # recalled_ring_state_r2 += 1\n",
    "                # recalled_ring_state_r3 += 1\n",
    "\n",
    "#                     ring1_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 1 Index\"] == recalled_ring_state_r1][\"Source Device\"]\n",
    "#                     ring2_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 2 Index\"] == recalled_ring_state_r2][\"Source Device\"]\n",
    "#                     ring3_injection_device = input_device_to_ring_cells_connections[pa_to_pyramidal_connections[\"Ring 3 Index\"] == recalled_ring_state_r3][\"Source Device\"]\n",
    "\n",
    "                #try:\n",
    "\n",
    "                input_device = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Source Device'].values[0])\n",
    "\n",
    "                #except:\n",
    "\n",
    "                    #print(f\"Query unsuccessful; likely corrective input targets do not exist on ring. Corrective input targets 1,2,3: {recalled_ring_state_r1},{recalled_ring_state_r2},{recalled_ring_state_r3}\")\n",
    "\n",
    "                #print(f\"Latest exc spike time: {sim.GetStatus(exc_spikes[0])[0]['events']['times'][-1]}\")\n",
    "\n",
    "                target_exc_cell_r1 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 1 Index'].values[0])\n",
    "                target_exc_cell_r2 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 2 Index'].values[0])\n",
    "                target_exc_cell_r3 = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Ring 3 Index'].values[0])\n",
    "\n",
    "                #print(f\"Injecting with device {input_device} targetting RPs: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)} at time {t}, timestep: {tick} until {t+correction_duration}\")\n",
    "\n",
    "                if t > start_delay:\n",
    "                \n",
    "                    injection_state_history[tick:tick+int(correction_duration // 20), 0, target_exc_cell_r1] = 1\n",
    "                    injection_state_history[tick:tick+int(correction_duration // 20), 1, target_exc_cell_r2] = 1\n",
    "                    injection_state_history[tick:tick+int(correction_duration // 20), 2, target_exc_cell_r3] = 1\n",
    "                \n",
    "            elif best_match_value < recall_threshold:\n",
    "\n",
    "                new_memories += 1\n",
    "\n",
    "                sense_memories.append(representations[representation_index])\n",
    "\n",
    "                location_memories.append(current_most_active_rp)\n",
    "\n",
    "            else:\n",
    "\n",
    "                print(\"Help\")\n",
    "\n",
    "\n",
    "            if no_spike_timeout <= 0:\n",
    "\n",
    "                print(f\"No spikes have been recorded for {no_spike_timeout} input cycles, stopping...\")\n",
    "\n",
    "                break\n",
    "\n",
    "            if representation_index < (len(representation_times) - 1):\n",
    "\n",
    "                representation_index += 1\n",
    "\n",
    "        print(f\"Timestep: {tick+1}/{len(time_deltas)}; Sim Time: {int(t)}; Ring State: {current_most_active_exc}; RP State: {current_most_active_rp}; Injection Sites: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)}; Memories Stored: {new_memories}; Recall events: {recalls}\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b32d1f-94aa-41b7-86de-4e249679febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_most_active_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c907bd8-1e84-4eb1-a988-8ff7e2c924d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a23c4-c28d-4915-a71a-b127947d091a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(injection_state_history[:,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2bae09-8296-4de7-81fb-99136d3d10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_device_to_ring_cells_connections"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b92f4d8-1c56-43d2-9d26-3843cafd4632",
   "metadata": {},
   "source": [
    "# Static frames of ring activity per time window\n",
    "\n",
    "cell_indices_for_plotting = (np.linspace(0, 2*np.pi, num = N_ex, endpoint = False) + ((2*np.pi) / N_ex)) % 120\n",
    "\n",
    "most_active_cell_indices = ((np.argmax(exc_state_history, axis = 2) + 1) / N_ex * 2*np.pi) % 120\n",
    "most_active_cell_values = np.max(exc_state_history, axis = 2)\n",
    "\n",
    "N_display_samples = 15\n",
    "\n",
    "timesteps_per_plot = history_timestep_window\n",
    "\n",
    "fig, ax = plt.subplots(N_display_samples, rings, subplot_kw={'projection': 'polar'}, figsize = (5 * rings, 5 * N_display_samples))\n",
    "\n",
    "for r, row in enumerate(ax):\n",
    "    \n",
    "    for c, column in enumerate(row):\n",
    "        \n",
    "        display_time = r * timesteps_per_plot + start_delay\n",
    "        display_origin_offset = -np.max(exc_state_history[display_time, c, :])\n",
    "        \n",
    "        ax[r, c].set_xticks(np.linspace(0, 2*np.pi, num = N_ex//10, endpoint = False))\n",
    "        ax[r, c].set_xticklabels(np.arange(0, N_ex, step = 10))\n",
    "        ax[r, c].set_rticks([0, np.max(exc_state_history[display_time, c, :]) // 2, np.max(exc_state_history[display_time, c, :])])\n",
    "        \n",
    "        ax[r, c].text(display_origin_offset, display_origin_offset, f\"{display_time}\", fontsize = 30, horizontalalignment = 'center', verticalalignment = 'center')\n",
    "        \n",
    "        ax[r, c].set_rorigin(display_origin_offset)\n",
    "        \n",
    "        if time[display_time] not in representation_times:\n",
    "        \n",
    "            ax[r, c].bar(cell_indices_for_plotting, exc_state_history[display_time, c, :], width = 0.1, color = 'green')\n",
    "            ax[r, c].bar(most_active_cell_indices[display_time, c], most_active_cell_values[display_time, c], width = 0.05, color = 'red')\n",
    "        \n",
    "        elif time[display_time] in representation_times:\n",
    "            \n",
    "            ax[r, c].bar(cell_indices_for_plotting, exc_state_history[display_time, c, :], width = 0.1, color = 'blue')\n",
    "            ax[r, c].bar(most_active_cell_indices[display_time, c], most_active_cell_values[display_time, c], width = 0.05, color = 'red')\n",
    "            \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745245c-9f16-49ab-bb7c-4bcbdbdcef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"exc_state_history.npy\", exc_state_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a69304-328f-482e-980b-a1bcab9d8f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['animation.embed_limit'] = 500.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b806fd0-748e-419f-a33d-314aaf23bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2ring(x, y, offset):\n",
    "\n",
    "    if not isinstance(x, np.ndarray):\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "    if not isinstance(y, np.ndarray):\n",
    "\n",
    "        y = np.array(y)\n",
    "\n",
    "    assert x.size == y.size\n",
    "    assert x.size > 0\n",
    "\n",
    "    if x.size == 1:\n",
    "\n",
    "        projection_r1 = np.dot(np.array([x, y]), np.array([x, -x / np.tan(np.radians(offset))])) / np.linalg.norm(np.array([x, -x / np.tan(np.radians(offset))]))\n",
    "        projection_r2 = np.dot(np.array([x, y]), np.array([x, -x / np.tan(np.radians(60 + offset))])) / np.linalg.norm(np.array([x, -x / np.tan(np.radians(60 + offset))]))\n",
    "        projection_r3 = np.dot(np.array([x, y]), np.array([x, x / np.tan(np.radians(60 - offset))])) / np.linalg.norm(np.array([x, x / np.tan(np.radians(60 - offset))]))\n",
    "\n",
    "    elif x.size > 1:\n",
    "\n",
    "        projection_r1 = np.array([np.dot(np.array([i, j]), np.array([i, -i / np.tan(np.radians(offset))])) / np.linalg.norm(np.array([i, -i / np.tan(np.radians(offset))])) for i, j in zip(x, y)])\n",
    "        projection_r2 = np.array([np.dot(np.array([i, j]), np.array([i, -i / np.tan(np.radians(60 + offset))])) / np.linalg.norm(np.array([i, -i / np.tan(np.radians(60 + offset))])) for i, j in zip(x, y)])\n",
    "        projection_r3 = np.array([np.dot(np.array([i, j]), np.array([i, i / np.tan(np.radians(60 - offset))])) / np.linalg.norm(np.array([i, i / np.tan(np.radians(60 - offset))])) for i, j in zip(x, y)])\n",
    "        \n",
    "\n",
    "    else:\n",
    "\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    offset = offset % 360\n",
    "\n",
    "    if offset >= 0 and offset < 60:\n",
    "\n",
    "        ring1 = -np.sign(x) * projection_r1\n",
    "        ring2 = -np.sign(x) * projection_r2\n",
    "        ring3 = -np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 60 and offset < 120:\n",
    "\n",
    "        ring1 = -np.sign(x) * projection_r1\n",
    "        ring2 = -np.sign(x) * projection_r2\n",
    "        ring3 = np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 120 and offset < 180:\n",
    "\n",
    "        ring1 = -np.sign(x) * projection_r1\n",
    "        ring2 = np.sign(x) * projection_r2\n",
    "        ring3 = np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 180 and offset < 240:\n",
    "\n",
    "        ring1 = np.sign(x) * projection_r1\n",
    "        ring2 = np.sign(x) * projection_r2\n",
    "        ring3 = np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 240 and offset < 300:\n",
    "\n",
    "        ring1 = np.sign(x) * projection_r1\n",
    "        ring2 = np.sign(x) * projection_r2\n",
    "        ring3 = -np.sign(x) * projection_r3\n",
    "\n",
    "    elif offset >= 300 and offset < 360:\n",
    "\n",
    "        ring1 = np.sign(x) * projection_r1\n",
    "        ring2 = -np.sign(x) * projection_r2\n",
    "        ring3 = -np.sign(x) * projection_r3\n",
    "\n",
    "    return np.array([ring1, ring2, ring3]).T\n",
    "\n",
    "def ring2cart(ring1, ring2, ring3, offset):\n",
    "\n",
    "    if not isinstance(ring1, np.ndarray):\n",
    "\n",
    "        ring1 = np.array(ring1)\n",
    "\n",
    "    if not isinstance(ring2, np.ndarray):\n",
    "\n",
    "        ring2 = np.array(ring2)\n",
    "\n",
    "    if not isinstance(ring3, np.ndarray):\n",
    "\n",
    "        ring3 = np.array(ring3)\n",
    "\n",
    "    assert ring1.size > 0    \n",
    "    \n",
    "    danger_values_r1 = [x for x in range(0, 360, 90)] # r1 will align with x or y at these offset values\n",
    "    danger_values_r2 = [x for x in range(30, 360, 90)] # r2 will align with x or y at these offset values\n",
    "    danger_values_r3 = [x for x in range(60, 360, 90)] # r3 will align with x or y at these offset values\n",
    "    \n",
    "    ### New method: Use intersection of normals to find the corresponding (x,y) \n",
    "    \n",
    "    # Draw ring axes that span the length of the arena in question\n",
    "    # The maximum extent of x and y are equal to the longest ring\n",
    "    # The largest ratio of ring:cartesian values are if a ring axis is aligned exactly to x or y\n",
    "    # Therefore, no point in ring space can be outside the corresponding bounds in cartesian space\n",
    "\n",
    "    offset = offset % 360\n",
    "    \n",
    "    if offset not in danger_values_r1 and offset not in danger_values_r2 and offset not in danger_values_r3:\n",
    "    \n",
    "        max_x = np.max([ring1, ring2, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "        \n",
    "        ring1_y = ring1 / np.cos(np.radians(offset))\n",
    "        ring2_y = ring2 / np.cos(np.radians(60 + offset))\n",
    "        ring3_y = -ring3 / np.cos(np.radians(60 - offset))\n",
    "\n",
    "        y_r1_n_start    =  -max_x * np.tan(np.radians(offset)) + ring1_y\n",
    "        y_r1_n_end      =  -min_x * np.tan(np.radians(offset)) + ring1_y\n",
    "\n",
    "        y_r2_n_start    =  -max_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        y_r2_n_end      =  -min_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "\n",
    "        y_r3_n_start    =  max_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        y_r3_n_end      =  min_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        \n",
    "        # Get start and end points of ring axes\n",
    "        \n",
    "        start_r1_n = np.array([min_x, y_r1_n_start])\n",
    "        start_r2_n = np.array([min_x, y_r2_n_start])\n",
    "        start_r3_n = np.array([min_x, y_r3_n_start])\n",
    "\n",
    "        end_r1_n = np.array([max_x, y_r1_n_end])\n",
    "        end_r2_n = np.array([max_x, y_r2_n_end])\n",
    "        end_r3_n = np.array([max_x, y_r3_n_end])\n",
    "        \n",
    "        x_values = np.empty(shape = (ring1.size, 3))\n",
    "        y_values = np.empty(shape = (ring1.size, 3))\n",
    "        \n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r2_n\n",
    "        x4,y4 = end_r2_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "\n",
    "        x1,y1 = start_r2_n\n",
    "        x2,y2 = end_r2_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 1] = x\n",
    "        y_values[:, 1] = y\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 2] = x\n",
    "        y_values[:, 2] = y\n",
    "    \n",
    "    elif offset in danger_values_r1:\n",
    "        \n",
    "        max_x = np.max([ring2, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "        \n",
    "        ring2_y = ring2 / np.cos(np.radians(60 + offset))\n",
    "        ring3_y = -ring3 / np.cos(np.radians(60 - offset))\n",
    "\n",
    "        y_r2_n_start    =  -max_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        y_r2_n_end      =  -min_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "\n",
    "        y_r3_n_start    =  max_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        y_r3_n_end      =  min_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        \n",
    "        # Get start and end points of ring axes\n",
    "        \n",
    "        start_r2_n = np.array([min_x, y_r2_n_start])\n",
    "        start_r3_n = np.array([min_x, y_r3_n_start])\n",
    "\n",
    "        end_r2_n = np.array([max_x, y_r2_n_end])\n",
    "        end_r3_n = np.array([max_x, y_r3_n_end])\n",
    "        \n",
    "        x_values = np.empty(shape = (ring1.size, 1))\n",
    "        y_values = np.empty(shape = (ring1.size, 1))\n",
    "        \n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r2_n\n",
    "        x2,y2 = end_r2_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "        \n",
    "    elif offset in danger_values_r2:\n",
    "        \n",
    "        max_x = np.max([ring1, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "        \n",
    "        ring1_y = ring1 / np.cos(np.radians(offset))\n",
    "        ring3_y = -ring3 / np.cos(np.radians(60 - offset))\n",
    "\n",
    "        y_r1_n_start    =  -max_x * np.tan(np.radians(offset)) + ring1_y\n",
    "        y_r1_n_end      =  -min_x * np.tan(np.radians(offset)) + ring1_y\n",
    "\n",
    "        y_r3_n_start    =  max_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        y_r3_n_end      =  min_x * np.tan(np.radians(60 - offset)) + ring3_y\n",
    "        \n",
    "        # Get start and end points of ring axes\n",
    "        \n",
    "        start_r1_n = np.array([min_x, y_r1_n_start])\n",
    "        start_r3_n = np.array([min_x, y_r3_n_start])\n",
    "\n",
    "        end_r1_n = np.array([max_x, y_r1_n_end])\n",
    "        end_r3_n = np.array([max_x, y_r3_n_end])\n",
    "        \n",
    "        x_values = np.empty(shape = (ring1.size, 1))\n",
    "        y_values = np.empty(shape = (ring1.size, 1))\n",
    "        \n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r3_n\n",
    "        x4,y4 = end_r3_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "        \n",
    "    elif offset in danger_values_r3:\n",
    "        \n",
    "        max_x = np.max([ring2, ring3], axis = 0) / np.cos(np.radians(np.max([offset, offset + 60, offset + 120])))\n",
    "        min_x = -max_x\n",
    "        \n",
    "        ring1_y = ring1 / np.cos(np.radians(offset))\n",
    "        ring2_y = ring2 / np.cos(np.radians(60 + offset))\n",
    "\n",
    "        y_r1_n_start    =  -max_x * np.tan(np.radians(offset)) + ring1_y\n",
    "        y_r1_n_end      =  -min_x * np.tan(np.radians(offset)) + ring1_y\n",
    "\n",
    "        y_r2_n_start    =  -max_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        y_r2_n_end      =  -min_x * np.tan(np.radians(60 + offset)) + ring2_y\n",
    "        \n",
    "        # Get start and end points of ring axes\n",
    "        \n",
    "        start_r1_n = np.array([min_x, y_r1_n_start])\n",
    "        start_r2_n = np.array([min_x, y_r2_n_start])\n",
    "\n",
    "        end_r1_n = np.array([max_x, y_r1_n_end])\n",
    "        end_r2_n = np.array([max_x, y_r2_n_end])\n",
    "        \n",
    "        x_values = np.empty(shape = (ring1.size, 1))\n",
    "        y_values = np.empty(shape = (ring1.size, 1))\n",
    "        \n",
    "        # Calculate where each pair intersects\n",
    "\n",
    "        x1,y1 = start_r1_n\n",
    "        x2,y2 = end_r1_n\n",
    "        x3,y3 = start_r2_n\n",
    "        x4,y4 = end_r2_n\n",
    "\n",
    "        denom = (y4-y3)*(x2-x1) - (x4-x3)*(y2-y1)\n",
    "        \n",
    "        ua = ((x4-x3)*(y1-y3) - (y4-y3)*(x1-x3)) / denom\n",
    "        ub = ((x2-x1)*(y1-y3) - (y2-y1)*(x1-x3)) / denom\n",
    "        x = x3 + ua * (x4-x3)\n",
    "        y = y3 + ua * (y4-y3)\n",
    "\n",
    "        x_values[:, 0] = x\n",
    "        y_values[:, 0] = y\n",
    "        \n",
    "\n",
    "    x = np.squeeze(np.mean(x_values, axis = 1))\n",
    "    y = np.squeeze(np.mean(np.array(y_values), axis = 1))\n",
    "    \n",
    "    x[np.isnan(x)] = 0\n",
    "    y[np.isnan(y)] = 0\n",
    "    \n",
    "    return np.array([x, y]).T\n",
    "\n",
    "def wrap_to_distance(distance, boundary):\n",
    "    \n",
    "    wrapped = distance.copy()\n",
    "    \n",
    "    wrapped[distance > 0] = distance[distance > 0] % boundary\n",
    "    wrapped[distance < 0] = distance[distance < 0] % boundary\n",
    "    \n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd6c59-bec3-49f1-a4aa-29a669315303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "ground_truth_ring_display = False\n",
    "\n",
    "for_export = True\n",
    "\n",
    "tick_label_colour = 'red'\n",
    "\n",
    "metric_plot = 'distance'\n",
    "\n",
    "cumulative_or_mean = 'mean'\n",
    "\n",
    "fig = plt.figure(figsize = (5 * rings, 10))\n",
    "\n",
    "if for_export:\n",
    "\n",
    "    ring_figure, pos_figure = fig.subfigures(2, 1, height_ratios = [5,4], hspace = 0, facecolor = 'w')\n",
    "    text_colour = 'black'\n",
    "\n",
    "else:\n",
    "    \n",
    "    ring_figure, pos_figure = fig.subfigures(2, 1, height_ratios = [5,4], hspace = 0)\n",
    "    text_colour = 'white'\n",
    "\n",
    "ring_plot = ring_figure.subplots(1, rings, subplot_kw={'projection': 'polar'})#, gridspec_kw = {'bottom': -0.5})\n",
    "gt_plot, est_plot, corr_plot = pos_figure.subplots(1, 3, subplot_kw={'projection': 'rectilinear'})#, gridspec_kw = {'width_ratios': [1,2,1]})\n",
    "p_plot = corr_plot.twinx()\n",
    "\n",
    "gt_plot.set_title(\"Ground Truth XY\", color = text_colour)\n",
    "est_plot.set_title(\"Estimated XY\", color = text_colour)\n",
    "\n",
    "gt_plot.set_xlabel(\"X\", color = text_colour)\n",
    "gt_plot.set_ylabel(\"Y\", color = text_colour)\n",
    "est_plot.set_xlabel(\"X\", color = text_colour)\n",
    "est_plot.set_ylabel(\"Y\", color = text_colour)\n",
    "corr_plot.set_xlabel(\"Timestamp\", color = text_colour)\n",
    "\n",
    "gt_plot.tick_params(axis='x', colors = tick_label_colour)\n",
    "gt_plot.tick_params(axis='y', colors = tick_label_colour)\n",
    "est_plot.tick_params(axis='x', colors = tick_label_colour)\n",
    "est_plot.tick_params(axis='y', colors = tick_label_colour)\n",
    "corr_plot.tick_params(axis='x', colors = tick_label_colour)\n",
    "corr_plot.tick_params(axis='y', colors = tick_label_colour)\n",
    "p_plot.tick_params(axis='y', colors = tick_label_colour)\n",
    "\n",
    "if metric_plot == 'spearman':\n",
    "\n",
    "    corr_plot.set_title(\"Spearman Correlation\", color = text_colour)\n",
    "    corr_plot.set_ylabel(\"Spearman's R\", color = text_colour)\n",
    "    p_plot.set_ylabel(\"P-value\", color = text_colour)\n",
    "    \n",
    "elif metric_plot == 'error':\n",
    "\n",
    "    corr_plot.set_title(\"Manhattan Error\", color = text_colour)\n",
    "    corr_plot.set_ylabel(\"Point-wise\", color = text_colour)\n",
    "    \n",
    "    if cumulative_or_mean == 'cumulative':\n",
    "    \n",
    "        p_plot.set_ylabel(\"Cumulative\", color = text_colour)\n",
    "        \n",
    "    elif cumulative_or_mean == 'mean':\n",
    "    \n",
    "        p_plot.set_ylabel(\"Mean\", color = text_colour)\n",
    "    \n",
    "elif metric_plot == 'distance':\n",
    "\n",
    "    corr_plot.set_title(\"Euclidean Error\", color = text_colour)\n",
    "    corr_plot.set_ylabel(\"Point-wise\", color = text_colour)\n",
    "    \n",
    "    if cumulative_or_mean == 'cumulative':\n",
    "    \n",
    "        p_plot.set_ylabel(\"Cumulative\", color = text_colour)\n",
    "        \n",
    "    elif cumulative_or_mean == 'mean':\n",
    "    \n",
    "        p_plot.set_ylabel(\"Mean\", color = text_colour)\n",
    "\n",
    "pos_figure.subplots_adjust(wspace = 0.3)\n",
    "\n",
    "cell_indices_for_plotting = (np.linspace(0, 2*np.pi, num = N_ex, endpoint = False) + ((2*np.pi) / N_ex)) % N_ex\n",
    "\n",
    "most_active_cell_indices = ((np.argmax(exc_state_history, axis = 2) + 1) / N_ex * 2*np.pi) % N_ex\n",
    "most_active_cell_values = np.max(exc_state_history, axis = 2)\n",
    "\n",
    "for c, column in enumerate(ring_plot):\n",
    "        \n",
    "    #display_time = r * timesteps_per_plot + start_delay\n",
    "    display_origin_offset = -np.max(exc_state_history[0, c, :])\n",
    "\n",
    "    ring_plot[c].set_xticks(np.linspace(0, 2*np.pi, num = N_ex//10, endpoint = False))\n",
    "    ring_plot[c].set_xticklabels(np.arange(0, N_ex, step = 10), color = tick_label_colour)\n",
    "    ring_plot[c].set_rticks([0, np.max(exc_state_history[start_delay, c, :]) // 2, np.max(exc_state_history[start_delay, c, :])])\n",
    "\n",
    "    ring_plot[c].set_rorigin(display_origin_offset)\n",
    "\n",
    "ring1_bar = ring_plot[0].bar(cell_indices_for_plotting, exc_state_history[start_delay, 0, :], width = 0.1, color = 'green')\n",
    "ring2_bar = ring_plot[1].bar(cell_indices_for_plotting, exc_state_history[start_delay, 1, :], width = 0.1, color = 'green')\n",
    "ring3_bar = ring_plot[2].bar(cell_indices_for_plotting, exc_state_history[start_delay, 2, :], width = 0.1, color = 'green')\n",
    "\n",
    "ring1_inj_bar = ring_plot[0].bar(cell_indices_for_plotting, injection_state_history[start_delay, 0, :], width = 0.05, color = 'blue')\n",
    "ring2_inj_bar = ring_plot[1].bar(cell_indices_for_plotting, injection_state_history[start_delay, 1, :], width = 0.05, color = 'blue')\n",
    "ring3_inj_bar = ring_plot[2].bar(cell_indices_for_plotting, injection_state_history[start_delay, 2, :], width = 0.05, color = 'blue')\n",
    "\n",
    "ring1_display_origin_offset = -np.max(exc_state_history[start_delay, 0, :])\n",
    "ring2_display_origin_offset = -np.max(exc_state_history[start_delay, 1, :])\n",
    "ring3_display_origin_offset = -np.max(exc_state_history[start_delay, 2, :])\n",
    "\n",
    "print(ring1_display_origin_offset)\n",
    "print(ring2_display_origin_offset)\n",
    "print(ring3_display_origin_offset)\n",
    "\n",
    "# ring1_text = ring_plot[0].text(ring1_display_origin_offset, ring1_display_origin_offset, f\"{start_delay}\", fontsize = 30, c = 'white', horizontalalignment = 'center', verticalalignment = 'center')\n",
    "# ring2_text = ring_plot[1].text(ring2_display_origin_offset, ring2_display_origin_offset, f\"{start_delay}\", fontsize = 30, c = 'white', horizontalalignment = 'center', verticalalignment = 'center')\n",
    "# ring3_text = ring_plot[2].text(ring3_display_origin_offset, ring3_display_origin_offset, f\"{start_delay}\", fontsize = 30, c = 'white', horizontalalignment = 'center', verticalalignment = 'center')\n",
    "\n",
    "ring1_text = ring_plot[0].text(ring1_display_origin_offset, ring1_display_origin_offset, \"0\\N{DEGREE SIGN}\", fontsize = 30, c = text_colour, horizontalalignment = 'center', verticalalignment = 'center')\n",
    "ring2_text = ring_plot[1].text(ring2_display_origin_offset, ring2_display_origin_offset, \"60\\N{DEGREE SIGN}\", fontsize = 30, c = text_colour, horizontalalignment = 'center', verticalalignment = 'center')\n",
    "ring3_text = ring_plot[2].text(ring3_display_origin_offset, ring3_display_origin_offset, \"120\\N{DEGREE SIGN}\", fontsize = 30, c = text_colour, horizontalalignment = 'center', verticalalignment = 'center')\n",
    "\n",
    "print(len(timestamps))\n",
    "print(len(exc_state_history))\n",
    "\n",
    "ring_1_unwrapped = np.unwrap(np.argmax(exc_state_history[:, 0, :], axis = 1), period = N_ex)\n",
    "ring_2_unwrapped = np.unwrap(np.argmax(exc_state_history[:, 1, :], axis = 1), period = N_ex)\n",
    "ring_3_unwrapped = np.unwrap(np.argmax(exc_state_history[:, 2, :], axis = 1), period = N_ex)\n",
    "\n",
    "ring_xy = ring2cart(ring_1_unwrapped, ring_2_unwrapped, ring_3_unwrapped, offset = -90)\n",
    "\n",
    "ring_xy[:, 0] = (ring_xy[:, 0] - min(ring_xy[:, 0])) / (max(ring_xy[:, 0]) - min(ring_xy[:, 0]))\n",
    "ring_xy[:, 1] = (ring_xy[:, 1] - min(ring_xy[:, 1])) / (max(ring_xy[:, 1]) - min(ring_xy[:, 1]))\n",
    "\n",
    "ring_xy[:, 0] = ring_xy[:, 0] * (max(pos_x) - min(pos_x)) + min(pos_x)\n",
    "ring_xy[:, 1] = ring_xy[:, 1] * (max(pos_y) - min(pos_y)) + min(pos_y)\n",
    "\n",
    "# Rescale to make trajectories comparable visually\n",
    "\n",
    "gt_plot.set_xlim(min(pos_x[start_delay:]), max(pos_x[start_delay:]))\n",
    "gt_plot.set_ylim(min(pos_y[start_delay:]), max(pos_y[start_delay:]))\n",
    "\n",
    "est_plot.set_xlim(min(ring_xy[start_delay:,0]), max(ring_xy[start_delay:,0]))\n",
    "est_plot.set_ylim(min(ring_xy[start_delay:,1]), max(ring_xy[start_delay:,1]))\n",
    "\n",
    "ground_truth_trajectory = gt_plot.scatter(pos_x[start_delay], pos_y[start_delay], c = 'DodgerBlue', marker = '.')\n",
    "ground_truth_position = gt_plot.scatter(pos_x[start_delay], pos_y[start_delay], c = 'DeepSkyBlue', marker = 'o')\n",
    "\n",
    "estimated_trajectory = est_plot.scatter(ring_xy[start_delay,0], ring_xy[start_delay,1], c = 'SeaGreen', marker = '.')\n",
    "estimated_position = est_plot.scatter(ring_xy[start_delay,0], ring_xy[start_delay,1], c = 'MediumSeaGreen', marker = 'o')\n",
    "\n",
    "if metric_plot == 'spearman':\n",
    "    \n",
    "    ground_truth_vector_magnitude = np.sqrt(pos_x[start_delay:] ** 2 + pos_y[start_delay:] ** 2)\n",
    "    estimated_vector_magnitude = np.sqrt(ring_xy[start_delay:,0] ** 2 + ring_xy[start_delay:,1] ** 2)\n",
    "\n",
    "    spearman_r_over_time = [spearmanr(ground_truth_vector_magnitude[:i+2], estimated_vector_magnitude[:i+2], alternative = 'greater')[0] for i in range(len(pos_x[start_delay:])-1)]\n",
    "    spearman_p_over_time = [spearmanr(ground_truth_vector_magnitude[:i+3], estimated_vector_magnitude[:i+3], alternative = 'greater')[1] for i in range(len(pos_x[start_delay:])-1)]\n",
    "\n",
    "    metric_per_timestep_plot, = corr_plot.plot([], [], c = 'red')\n",
    "    metric_cumulative_plot, = p_plot.plot([], [], c = 'purple')\n",
    "    \n",
    "#     corr_plot.set_xlim(start_delay, start_delay + len(spearman_r_over_time))\n",
    "#     corr_plot.set_ylim(-1, 1)\n",
    "    \n",
    "#     p_plot.set_ylim(0, 1)\n",
    "    \n",
    "elif metric_plot == 'error':\n",
    "    \n",
    "    pointwise_error_over_time = np.abs(pos_x[:] - ring_xy[:, 0]) + np.abs(pos_y[:] - ring_xy[:, 1])\n",
    "    cumulative_error_over_time = np.cumsum(pointwise_error_over_time)\n",
    "        \n",
    "    if cumulative_or_mean == 'mean':\n",
    "    \n",
    "        cumulative_error_over_time = cumulative_error_over_time / np.arange(1, len(cumulative_error_over_time) + 1)\n",
    "    \n",
    "    metric_per_timestep_plot, = corr_plot.plot([], [], c = 'red')\n",
    "    metric_cumulative_plot, = p_plot.plot([], [], c = 'purple')\n",
    "    \n",
    "#     corr_plot.set_xlim(start_delay, start_delay + len(pointwise_error_over_time))\n",
    "#     corr_plot.set_ylim(0, max(pointwise_error_over_time))\n",
    "    \n",
    "#     p_plot.set_ylim(0, max(cumulative_error_over_time))\n",
    "    \n",
    "elif metric_plot == 'distance':\n",
    "    \n",
    "    pointwise_distance_over_time = np.sqrt((pos_x[:] - ring_xy[:, 0]) ** 2 + (pos_y[:] - ring_xy[:, 1]) ** 2)\n",
    "    cumulative_distance_over_time = np.cumsum(pointwise_distance_over_time)\n",
    "    \n",
    "    if cumulative_or_mean == 'mean':\n",
    "    \n",
    "        cumulative_distance_over_time = cumulative_distance_over_time / np.arange(1, len(cumulative_distance_over_time) + 1)\n",
    "    \n",
    "    metric_per_timestep_plot, = corr_plot.plot([], [], c = 'red')\n",
    "    metric_cumulative_plot, = p_plot.plot([], [], c = 'purple')\n",
    "    \n",
    "#     corr_plot.set_xlim(start_delay, start_delay + len(pointwise_distance_over_time))\n",
    "#     corr_plot.set_ylim(0, max(pointwise_distance_over_time))\n",
    "    \n",
    "#     p_plot.set_ylim(0, max(cumulative_distance_over_time))\n",
    "\n",
    "# Add bars to show ground truth on ring\n",
    "\n",
    "if ground_truth_ring_display:\n",
    "\n",
    "    gt_ring_values = np.round(cart2ring(pos_x[start_delay:] * I_vel * 0.01, pos_y[start_delay:] * I_vel * 0.01, offset = -90), 0).astype(int) % N_ex\n",
    "\n",
    "    ground_truth_history = np.zeros_like(exc_state_history[start_delay:])\n",
    "\n",
    "    ground_truth_history[np.arange(gt_ring_values.shape[0])[:, None], np.arange(gt_ring_values.shape[1]), gt_ring_values] = np.max(exc_state_history[start_delay:, ...], axis = 2)\n",
    "\n",
    "    ring1_gt_bar = ring_plot[0].bar(cell_indices_for_plotting, ground_truth_history[start_delay, 0], width = 0.075, color = 'blue')\n",
    "    ring2_gt_bar = ring_plot[1].bar(cell_indices_for_plotting, ground_truth_history[start_delay, 1], width = 0.075, color = 'blue')\n",
    "    ring3_gt_bar = ring_plot[2].bar(cell_indices_for_plotting, ground_truth_history[start_delay, 2], width = 0.075, color = 'blue')\n",
    "\n",
    "def animate(i):\n",
    "    \n",
    "    display_time = i * history_timestep_window + start_delay\n",
    "    \n",
    "    print(display_time, end = '\\r')\n",
    "    \n",
    "    # Ring figures updates\n",
    "    \n",
    "    for c, column in enumerate(ring_plot):\n",
    "        \n",
    "        display_origin_offset = -np.max(exc_state_history[display_time, c, :])\n",
    "        ring_plot[c].set_rorigin(display_origin_offset)\n",
    "        ring_plot[c].set_rticks([0, np.max(exc_state_history[display_time, c, :]) // 2, np.max(exc_state_history[display_time, c, :])])\n",
    "        ring_plot[c].set_rlim(0, np.max(exc_state_history[display_time, c, :]))\n",
    "        #ax[c].text(display_origin_offset, display_origin_offset, f\"{display_time}\", c = 'white', fontsize = 30, horizontalalignment = 'center', verticalalignment = 'center')\n",
    "    \n",
    "    ring1_text.set_position((-np.max(exc_state_history[display_time, 0, :]), -np.max(exc_state_history[display_time, 0, :])))\n",
    "    #ring1_text.set_text(f\"{display_time}\")\n",
    "    \n",
    "    for b, bar in enumerate(ring1_bar):\n",
    "        \n",
    "        bar.set_height(exc_state_history[display_time, 0, b])\n",
    "    \n",
    "    ring2_text.set_position((-np.max(exc_state_history[display_time, 1, :]), -np.max(exc_state_history[display_time, 1, :])))\n",
    "    #ring2_text.set_text(f\"{display_time}\")\n",
    "    \n",
    "    for b, bar in enumerate(ring2_bar):\n",
    "        \n",
    "        bar.set_height(exc_state_history[display_time, 1, b])\n",
    "    \n",
    "    ring3_text.set_position((-np.max(exc_state_history[display_time, 2, :]), -np.max(exc_state_history[display_time, 2, :])))\n",
    "    #ring3_text.set_text(f\"{display_time}\")\n",
    "    \n",
    "    for b, bar in enumerate(ring3_bar):\n",
    "        \n",
    "        bar.set_height(exc_state_history[display_time, 2, b])\n",
    "        \n",
    "    for b, bar in enumerate(ring1_inj_bar):\n",
    "\n",
    "        bar.set_height(injection_state_history[display_time, 0, b] * max(exc_state_history[display_time, 0, :]))\n",
    "\n",
    "    for b, bar in enumerate(ring2_inj_bar):\n",
    "\n",
    "        bar.set_height(injection_state_history[display_time, 1, b] * max(exc_state_history[display_time, 1, :]))\n",
    "\n",
    "    for b, bar in enumerate(ring3_inj_bar):\n",
    "\n",
    "        bar.set_height(injection_state_history[display_time, 2, b] * max(exc_state_history[display_time, 2, :]))\n",
    "    \n",
    "    if np.sum(injection_state_history[display_time, ...]) > 0:\n",
    "        \n",
    "        corr_plot.axvline(x = display_time, linestyle = '--', color = 'DodgerBlue', alpha = 0.5)\n",
    "        \n",
    "    # Ground truth bars\n",
    "    \n",
    "    if ground_truth_ring_display:\n",
    "    \n",
    "        for b, bar in enumerate(ring1_gt_bar):\n",
    "\n",
    "            bar.set_height(ground_truth_history[display_time, 0, b])\n",
    "\n",
    "        for b, bar in enumerate(ring2_gt_bar):\n",
    "\n",
    "            bar.set_height(ground_truth_history[display_time, 1, b])\n",
    "\n",
    "        for b, bar in enumerate(ring3_gt_bar):\n",
    "\n",
    "            bar.set_height(ground_truth_history[display_time, 2, b])\n",
    "    \n",
    "    # Position (and estimate) plot updates:\n",
    "    \n",
    "    if display_time > start_delay:\n",
    "    \n",
    "        ground_truth_trajectory.set_offsets(np.array([pos_x[start_delay:display_time:history_timestep_window], pos_y[start_delay:display_time:history_timestep_window]]).T)\n",
    "    \n",
    "        if i < 5:\n",
    "    \n",
    "            ground_truth_position.set_offsets(np.array([pos_x[start_delay:display_time:history_timestep_window], pos_y[start_delay:display_time:history_timestep_window]]).T)\n",
    "        \n",
    "        else:\n",
    "    \n",
    "            ground_truth_position.set_offsets(np.array([pos_x[display_time - 5 * history_timestep_window:display_time:history_timestep_window], pos_y[display_time - 5 * history_timestep_window:display_time:history_timestep_window]]).T)\n",
    "        \n",
    "\n",
    "        estimated_trajectory.set_offsets(np.array([ring_xy[start_delay:display_time:history_timestep_window,0], ring_xy[start_delay:display_time:history_timestep_window,1]]).T)\n",
    "        \n",
    "        if i < 5:\n",
    "        \n",
    "            estimated_position.set_offsets(np.array([ring_xy[start_delay:display_time:history_timestep_window,0], ring_xy[start_delay:display_time:history_timestep_window,1]]).T)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            estimated_position.set_offsets(np.array([ring_xy[display_time - 5 * history_timestep_window:display_time:history_timestep_window,0], ring_xy[display_time - 5 * history_timestep_window:display_time:history_timestep_window,1]]).T)\n",
    "        \n",
    "        if metric_plot == 'spearman':\n",
    "    \n",
    "            corr_plot.set_xlim(start_delay, start_delay + i * history_timestep_window + 1)\n",
    "            corr_plot.set_ylim(min(spearman_r_over_time[start_delay:display_time]), max(spearman_r_over_time[start_delay:display_time]))\n",
    "\n",
    "            metric_per_timestep_plot.set_data(range(start_delay, display_time, history_timestep_window), spearman_r_over_time[start_delay:display_time:history_timestep_window])\n",
    "\n",
    "            p_plot.set_ylim(0, max(spearman_p_over_time[start_delay:display_time]))\n",
    "            metric_cumulative_plot.set_data(range(start_delay, display_time, history_timestep_window), spearman_p_over_time[start_delay:display_time:history_timestep_window])\n",
    "            \n",
    "        elif metric_plot == 'error':\n",
    "            \n",
    "            corr_plot.set_xlim(start_delay, start_delay + i * history_timestep_window + 1)\n",
    "            corr_plot.set_ylim(min(pointwise_error_over_time[start_delay:display_time]), max(pointwise_error_over_time[start_delay:display_time]))\n",
    "\n",
    "            metric_per_timestep_plot.set_data(range(start_delay, display_time, history_timestep_window), pointwise_error_over_time[start_delay:display_time:history_timestep_window])\n",
    "\n",
    "            p_plot.set_ylim(0, max(cumulative_error_over_time[start_delay:display_time]))\n",
    "            metric_cumulative_plot.set_data(range(start_delay, display_time, history_timestep_window), cumulative_error_over_time[start_delay:display_time:history_timestep_window])\n",
    "            \n",
    "        elif metric_plot == 'distance':\n",
    "            \n",
    "            corr_plot.set_xlim(start_delay, start_delay + i * history_timestep_window + 1)\n",
    "            corr_plot.set_ylim(min(pointwise_distance_over_time[start_delay:display_time]), max(pointwise_distance_over_time[start_delay:display_time]))\n",
    "\n",
    "            metric_per_timestep_plot.set_data(range(start_delay, display_time, history_timestep_window), pointwise_distance_over_time[start_delay:display_time:history_timestep_window])\n",
    "\n",
    "            p_plot.set_ylim(0, max(cumulative_distance_over_time[start_delay:display_time]))\n",
    "            metric_cumulative_plot.set_data(range(start_delay, display_time, history_timestep_window), cumulative_distance_over_time[start_delay:display_time:history_timestep_window])\n",
    "        \n",
    "    if ground_truth_ring_display:\n",
    "    \n",
    "        return *ring1_bar, *ring2_bar, *ring3_bar, *ring1_inj_bar, *ring2_inj_bar, *ring3_inj_bar, *ring1_gt_bar, *ring2_gt_bar, *ring3_gt_bar, ring1_text, ring2_text, ring3_text, ground_truth_trajectory, ground_truth_position, estimated_trajectory, estimated_position, metric_per_timestep_plot, metric_cumulative_plot\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return *ring1_bar, *ring2_bar, *ring3_bar, *ring1_inj_bar, *ring2_inj_bar, *ring3_inj_bar, ring1_text, ring2_text, ring3_text, ground_truth_trajectory, ground_truth_position, estimated_trajectory, estimated_position, metric_per_timestep_plot, metric_cumulative_plot\n",
    "    \n",
    "ani = FuncAnimation(fig, animate, frames = (len(timestamps) // history_timestep_window) - (start_delay // history_timestep_window), blit = True)  \n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d6426-82d5-444c-b30e-0988d0e89b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(injection_state_history[injection_state_history > 0]) // 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1647f-6626-4f45-bb23-5a8a8669ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(exc_state_history[:, 0, :], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad5566-5fe4-4c3d-94e8-3c30d9b467a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Minimum Input = {minimum_input}\")\n",
    "if corrections:\n",
    "    print(f\"Correction Duration = {correction_duration}\")\n",
    "    print(f\"Correction Current = {correction_current}\")\n",
    "    print(f\"Confidence Scaling = {confidence_scaling}\")\n",
    "    print(f\"Recall Threshold = {recall_threshold}\")\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(f\"Memories Stored = {len(sense_memories)}\")\n",
    "    print(f\"Recalls = {recalls}\")\n",
    "print(\"-----------------------------------------\")\n",
    "print(f\"Mean Error = {cumulative_distance_over_time[-1]}\")\n",
    "print(f\"Final Position Error = {pointwise_distance_over_time[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4dd53c-6008-4c47-bffc-e7ee90903dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grid_cell_spikes = sim.GetStatus(pyramidal_spikes)[0]['events']['senders']\n",
    "\n",
    "spiking_neurons, count_spikes = np.unique(all_grid_cell_spikes, return_counts = True)\n",
    "\n",
    "most_active_grid_cell = spiking_neurons[np.argmax(count_spikes)]\n",
    "\n",
    "grid_cell_spike_timesteps = sim.GetStatus(pyramidal_spikes)[0]['events']['times'][np.argwhere(all_grid_cell_spikes == most_active_grid_cell)].squeeze() // 20\n",
    "\n",
    "grid_cell_spike_timesteps = grid_cell_spike_timesteps.astype(int)\n",
    "\n",
    "spike_locations_x = pos_x[grid_cell_spike_timesteps]\n",
    "spike_locations_y = pos_y[grid_cell_spike_timesteps]\n",
    "\n",
    "plt.scatter(pos_x, pos_y, marker = '.')\n",
    "plt.scatter(spike_locations_x, spike_locations_y, marker = '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48214b68-3673-4f38-88eb-a62882adcc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do:\n",
    "\n",
    "# Just realised that corrections appear better and more instantaneous than they actually are, as ring bump position is calculated using\n",
    "# the max spiking neuron. In a lot of cases during corrections, this will be the target of correction, rather than where the bump is\n",
    "\n",
    "# Consider calculating the circular mean instead\n",
    "# It will induce its own weirdness, especially when the bump center is far from the correction site, but might give a better impression of where the\n",
    "# bump actually is\n",
    "# Alternatively, the median spiking cell (from a subsample where spikes > 0, to avoid the median always being 0) might better land within the bump,\n",
    "# though it will bounce around more than max or mean\n",
    "\n",
    "# Need to decide whether the corrective input is a 'legitimate' part of the ring's activity or not. Arguably there shouldn't be any distinction\n",
    "# of induced vs native spikes in the ring, as there is no way for the neurons themselves to distinguish this"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d42bdc6e-0252-4891-8689-5381488ca3ae",
   "metadata": {},
   "source": [
    "print(f\"Minimum Input = {minimum_input}\")\n",
    "print(f\"Final R = {spearman_r_over_time[-1]}\")\n",
    "print(f\"Final P = {spearman_p_over_time[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefc16d-980e-41ff-b9e8-1c19deccc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f'animated_ring_plot__timestamps={len(timestamps)}_power={minimum_input}_corrections={corrections}.gif', savefig_kwargs={\"dpi\": 4000, \"transparent\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4e36dd-9272-49cc-8338-54255e5e32fa",
   "metadata": {},
   "source": [
    "## Testing above this line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56907268-6ab8-450c-937b-1e4b681dbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation in steps, pausing only when representations are available\n",
    "\n",
    "time_deltas = np.diff(time).astype(int)\n",
    "\n",
    "representation_time_deltas = np.diff(representation_times).astype(int)\n",
    "\n",
    "start_delay = 100\n",
    "\n",
    "no_spike_timeout = 5\n",
    "\n",
    "recalls = 0\n",
    "new_memories = 0\n",
    "\n",
    "sim.set_verbosity(18)\n",
    "\n",
    "correction_timesteps = 5\n",
    "correction_current = 500.\n",
    "\n",
    "exc_state_history_per_rep = np.zeros(shape = (len(representation_time_deltas), rings, N_ex))\n",
    "\n",
    "injection_or_not = np.full(shape = (len(representation_time_deltas)), fill_value = False, dtype = bool)\n",
    "\n",
    "if simulate_or_load == 'simulate':    \n",
    "    \n",
    "    with sim.RunManager():\n",
    "    \n",
    "        for time_delta, t, tick, representation in zip(representation_time_deltas, representation_times, range(len(representation_times)), representations):\n",
    "            \n",
    "            sim.Run(time_delta)\n",
    "            \n",
    "            ring1_exc, ring1_spikes_exc = np.unique(sim.GetStatus(exc_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "            ring2_exc, ring2_spikes_exc = np.unique(sim.GetStatus(exc_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "            ring3_exc, ring3_spikes_exc = np.unique(sim.GetStatus(exc_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "            \n",
    "            ring1_most_active_exc_index = np.argmax(ring1_spikes_exc) if ring1_spikes_exc.size > 0 else None\n",
    "            ring2_most_active_exc_index = np.argmax(ring2_spikes_exc) if ring2_spikes_exc.size > 0 else None\n",
    "            ring3_most_active_exc_index = np.argmax(ring3_spikes_exc) if ring3_spikes_exc.size > 0 else None\n",
    "            \n",
    "            current_exc_state = (ring1_most_active_exc_index, ring2_most_active_exc_index, ring3_most_active_exc_index)\n",
    "            \n",
    "            if np.all(None not in current_exc_state):\n",
    "            \n",
    "                exc_state_history_per_rep[tick, 0, ring1_exc-min(ring1_exc)] = ring1_spikes_exc\n",
    "                exc_state_history_per_rep[tick, 1, ring2_exc-min(ring2_exc)] = ring2_spikes_exc\n",
    "                exc_state_history_per_rep[tick, 2, ring3_exc-min(ring3_exc)] = ring3_spikes_exc\n",
    "            \n",
    "            ring1_rp, ring1_spikes_rp = np.unique(sim.GetStatus(pa_spikes[0])[0]['events']['senders'], return_counts = True)\n",
    "            ring2_rp, ring2_spikes_rp = np.unique(sim.GetStatus(pa_spikes[1])[0]['events']['senders'], return_counts = True)\n",
    "            ring3_rp, ring3_spikes_rp = np.unique(sim.GetStatus(pa_spikes[2])[0]['events']['senders'], return_counts = True)\n",
    "            \n",
    "            ring1_most_active_rp_index = np.argmax(ring1_spikes_rp) if ring1_spikes_rp.size > 0 else None\n",
    "            ring2_most_active_rp_index = np.argmax(ring2_spikes_rp) if ring2_spikes_rp.size > 0 else None\n",
    "            ring3_most_active_rp_index = np.argmax(ring3_spikes_rp) if ring3_spikes_rp.size > 0 else None\n",
    "            \n",
    "            ring1_most_active_rp = ring1_rp[ring1_most_active_rp_index] if ring1_most_active_rp_index is not None else None\n",
    "            ring2_most_active_rp = ring2_rp[ring2_most_active_rp_index] if ring2_most_active_rp_index is not None else None\n",
    "            ring3_most_active_rp = ring3_rp[ring3_most_active_rp_index] if ring3_most_active_rp_index is not None else None\n",
    "            \n",
    "            current_rp_state = (ring1_most_active_rp_index, ring2_most_active_rp_index, ring3_most_active_rp_index)\n",
    "            \n",
    "            if corrections == True and np.all(None not in current_rp_state):\n",
    "            \n",
    "                recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = -1, -1, -1\n",
    "            \n",
    "                if len(sense_memories) == 0:\n",
    "\n",
    "                    sense_memories.append(representation)\n",
    "\n",
    "                if len(location_memories) == 0:\n",
    "\n",
    "                    location_memories.append(current_rp_state)\n",
    "\n",
    "                pearson_coorelation = np.empty(shape = (len(sense_memories)))\n",
    "\n",
    "                for sm, sense_memory in enumerate(sense_memories):\n",
    "\n",
    "                    pearson_coorelation[sm] = 1 - pearsonr(representation, sense_memory)[0]\n",
    "\n",
    "                best_match_index = np.argmax(pearson_coorelation) if pearson_coorelation.size > 0 else None\n",
    "\n",
    "                best_match_element = sense_memories[best_match_index] if best_match_index is not None else None\n",
    "\n",
    "                best_match_value = pearson_coorelation[best_match_index] if best_match_index is not None else None\n",
    "                \n",
    "\n",
    "                if best_match_value is None and timestamp > start_delay:\n",
    "\n",
    "                    no_spike_timeout -= 1\n",
    "                    \n",
    "\n",
    "                elif best_match_value >= recall_threshold:\n",
    "\n",
    "                    recalls += 1\n",
    "                    \n",
    "                    recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3 = location_memories[best_match_index]\n",
    "                    \n",
    "                    input_device = int(input_device_to_ring_cells_connections.query(\"`Ring 1 Virtual RP` == @recalled_ring_state_r1 and `Ring 2 Virtual RP` == @recalled_ring_state_r2 and `Ring 3 Virtual RP` == @recalled_ring_state_r3\")['Source Device'].values[0])\n",
    "\n",
    "                    sim.SetStatus([input_device], {'amplitude_times': time[tick:tick+correction_timesteps],'amplitude_values': np.tile(correction_current, correction_timesteps)})\n",
    "                \n",
    "                    injection_or_not[tick] = True\n",
    "                            \n",
    "                elif best_match_value < recall_threshold:\n",
    "\n",
    "                    new_memories += 1\n",
    "\n",
    "                    sense_memories.append(representation)\n",
    "\n",
    "                    location_memories.append(current_rp_state)\n",
    "\n",
    "                \n",
    "                if no_spike_timeout <= 0:\n",
    "\n",
    "                    print(f\"No spikes have been recorded for {no_spike_timeout} input cycles, stopping...\")\n",
    "\n",
    "                    break\n",
    "                \n",
    "                print(f\"Experience: {tick+1}/{len(representation_time_deltas)}; Sim Time: {int(t)}; Ring State: {current_exc_state}; RP State: {current_rp_state}; Injection Sites: {(recalled_ring_state_r1, recalled_ring_state_r2, recalled_ring_state_r3)}; Memories Stored: {new_memories}; Recall events: {recalls}\", end = '\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c31dbc-a0d8-43d2-875f-69344f759c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static frames of ring activity during memory creation or recall\n",
    "\n",
    "cell_indices_for_plotting = np.linspace(0, 2*np.pi, num = N_ex)\n",
    "\n",
    "most_active_cell_indices = np.argmax(exc_state_history_per_rep, axis = 2) / N_ex * 2*np.pi\n",
    "most_active_cell_values = np.max(exc_state_history_per_rep, axis = 2)\n",
    "\n",
    "injection_indices = np.nonzero(injection_or_not)\n",
    "\n",
    "N_display_samples = 20\n",
    "\n",
    "fig, ax = plt.subplots(N_display_samples, rings, subplot_kw={'projection': 'polar'}, figsize = (5 * rings, 5 * N_display_samples))\n",
    "\n",
    "for r, row in enumerate(ax):\n",
    "    \n",
    "    for c, column in enumerate(row):\n",
    "        \n",
    "        ax[r, c].set_rorigin(-np.max(exc_state_history_per_rep[r, c, :]))\n",
    "        \n",
    "        if not injection_or_not[r]:\n",
    "        \n",
    "            ax[r, c].bar(cell_indices_for_plotting, exc_state_history_per_rep[r, c, :], width = 0.1, color = 'green')\n",
    "            ax[r, c].bar(most_active_cell_indices[r, c], most_active_cell_values[r, c], width = 0.1, color = 'red')\n",
    "            \n",
    "            ax[r, c].set_xticks(np.linspace(0, 2*np.pi, num = N_ex//10, endpoint = False))\n",
    "            ax[r, c].set_xticklabels(np.arange(0, N_ex, step = 10))\n",
    "        \n",
    "        elif injection_or_not[r]:\n",
    "            \n",
    "            ax[r, c].bar(cell_indices_for_plotting, exc_state_history_per_rep[r, c, :], width = 0.1, color = 'blue')\n",
    "            \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb8503-2143-4240-abc8-6a804c978a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(injection_or_not)\n",
    "\n",
    "injection_indices = location_memories[injection_or_not]\n",
    "\n",
    "print(injection_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec825784-2e2c-4ab1-9ce5-39769a10d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_x = pos_x[rat_injection_index]\n",
    "ground_truth_y = pos_y[rat_injection_index]\n",
    "\n",
    "noisy_r1 = np.argmax(exc_state_history_per_rep[1:, 0, :], axis = 1) - (N_ex / 2)\n",
    "noisy_r2 = np.argmax(exc_state_history_per_rep[1:, 1, :], axis = 1) - (N_ex / 2)\n",
    "noisy_r3 = np.argmax(exc_state_history_per_rep[1:, 2, :], axis = 1) - (N_ex / 2)\n",
    "\n",
    "print(noisy_r1.shape)\n",
    "\n",
    "# noisy_r1 = wrap_to_distance(noisy_r1, 120)\n",
    "# noisy_r2 = wrap_to_distance(noisy_r2, 120)\n",
    "# noisy_r3 = wrap_to_distance(noisy_r3, 120)\n",
    "\n",
    "noisy_xy = ring2cart(noisy_r1, noisy_r2, noisy_r3, offset = -90)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].scatter(ground_truth_x, ground_truth_y)\n",
    "ax[1].scatter(noisy_xy[:, 0], noisy_xy[:, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf3187f-c577-42d1-8108-a71f05acfb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if simulate_or_load == 'simulate':\n",
    "    \n",
    "    np.save(f\"excitatory_spikes_{N_pyramidals}_{spiral_or_rat}_{N_ex}_neurons_{int(mins)}_minutes.npy\", np.array([sim.GetStatus(exc_spikes[0]),\n",
    "                                                                               sim.GetStatus(exc_spikes[1]),\n",
    "                                                                               sim.GetStatus(exc_spikes[2])]))\n",
    "    np.save(f\"pa_spikes_{N_pyramidals}_{spiral_or_rat}_{N_ex}_neurons_{int(mins)}_minutes.npy\", np.array([sim.GetStatus(pa_spikes[0]),\n",
    "                                                                       sim.GetStatus(pa_spikes[1]),\n",
    "                                                                       sim.GetStatus(pa_spikes[2])]))\n",
    "    np.save(f\"pyramidal_spikes_{N_pyramidals}_{spiral_or_rat}_{N_ex}_neurons_{int(mins)}_minutes.npy\", sim.GetStatus(pyramidal_spikes))\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "    \n",
    "    exc_spikes = np.load(f\"excitatory_spikes_{N_pyramidals}_{spiral_or_rat}_{N_ex}_neurons_{int(mins)}_minutes.npy\", allow_pickle = True)\n",
    "    pa_spikes = np.load(f\"pa_spikes_{N_pyramidals}_{spiral_or_rat}_{N_ex}_neurons_{int(mins)}_minutes.npy\", allow_pickle = True)\n",
    "    pyramidal_spikes = np.load(f\"pyramidal_spikes_{N_pyramidals}_{spiral_or_rat}_{N_ex}_neurons_{int(mins)}_minutes.npy\", allow_pickle = True)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2664d35c-167e-4f8b-98b1-7b72f47da888",
   "metadata": {},
   "source": [
    "## Visualise spikes from run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6825f58-834a-4dde-85ae-0959c319aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View pyramidal cell firing\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# plot #4 comes first, as the most active pyramidal cell is used to index the dataframe of connection details \n",
    "# in order to get the relevant ring phase cells responsible\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(16,16),facecolor='w')\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    ev = sim.GetStatus(pyramidal_spikes)[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "\n",
    "    ev = pyramidal_spikes[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError\n",
    "\n",
    "# The most common occurence of cell ID is the most active cell\n",
    "# This is plotted to see what the maximally active cell is like, to check for any over-excitation\n",
    "    \n",
    "occurence_count = Counter(sp)\n",
    "pyramidal_cell = occurence_count.most_common(5)[0][0]\n",
    "\n",
    "# Below commented code is for if you want to get the relevant pyramidal cell from the 3 constituent ring phase cells\n",
    "\n",
    "# cell = pa_to_pyramidal_connections[(pa_to_pyramidal_connections[\"Ring 1 PA Cell\"] == ring_1_cell) & \n",
    "#                                    (pa_to_pyramidal_connections[\"Ring 2 PA Cell\"] == ring_2_cell) & \n",
    "#                                    (pa_to_pyramidal_connections[\"Ring 3 PA Cell\"] == ring_3_cell)\n",
    "#                                   ][\"Target Pyramidal Cell\"].tolist()[0]\n",
    "\n",
    "ring_1_cell = pa_to_pyramidal_connections[pa_to_pyramidal_connections[\"Target Pyramidal Cell\"] == pyramidal_cell][\"Ring 1 PA Cell\"].tolist()[0]\n",
    "\n",
    "ring_2_cell = pa_to_pyramidal_connections[pa_to_pyramidal_connections[\"Target Pyramidal Cell\"] == pyramidal_cell][\"Ring 2 PA Cell\"].tolist()[0]\n",
    "\n",
    "ring_3_cell = pa_to_pyramidal_connections[pa_to_pyramidal_connections[\"Target Pyramidal Cell\"] == pyramidal_cell][\"Ring 3 PA Cell\"].tolist()[0]\n",
    "\n",
    "print(pyramidal_cell)\n",
    "\n",
    "exc_state_history_per_rep[:, 0, :]\n",
    "\n",
    "print(len(sp==pyramidal_cell))\n",
    "\n",
    "spktms = time[sp==pyramidal_cell]\n",
    "spktms = (spktms//20)*20\n",
    "spktms=spktms[1:]\n",
    "\n",
    "print(len(spktms))\n",
    "print(len(time))\n",
    "\n",
    "xs = pos_x[np.where(np.isin(time, spktms))]\n",
    "ys = pos_y[np.where(np.isin(time, spktms))]\n",
    "\n",
    "ax4.set_title(\"Pyramidal Cells\")\n",
    "ax4.plot(pos_x,pos_y)\n",
    "ax4.plot(xs,ys,'.')\n",
    "\n",
    "if spiral_or_rat == 'spiral':\n",
    "\n",
    "    t = np.arange(0,sim_len,dt)*1.\n",
    "    time = [i * 1. for i in t if i < sim_len]\n",
    "\n",
    "elif spiral_or_rat == 'rat':\n",
    "    \n",
    "    #t = rat_dataset['post'].squeeze()\n",
    "    \n",
    "#     if concatenate_rat:\n",
    "        \n",
    "#         t_2 = rat_dataset_2['post'].squeeze()\n",
    "#         t_2 = t_2 + max(t) + 0.02\n",
    "#         t = np.concatenate([t, t_2])\n",
    "        \n",
    "    # t = t * 1000\n",
    "    \n",
    "    time = t\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    ev = sim.GetStatus(pa_spikes[0])[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "\n",
    "    ev = pa_spikes[0][0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError\n",
    "\n",
    "# The most common occurence of cell ID is the most active cell\n",
    "# This is plotted to see what the maximally active cell is like, to check for any over-excitation\n",
    "    \n",
    "#occurence_count = Counter(sp)\n",
    "#ring_1_cell = occurence_count.most_common(5)[0][0]\n",
    "\n",
    "spktms = t[sp==ring_1_cell]\n",
    "spktms = (spktms//20)*20\n",
    "spktms=spktms[1:]\n",
    "    \n",
    "xs = pos_x[np.where(np.isin(time, spktms))]\n",
    "ys = pos_y[np.where(np.isin(time, spktms))]\n",
    "\n",
    "ax1.set_title(\"PA Cells (Y-axis)\")\n",
    "ax1.plot(pos_x,pos_y)\n",
    "ax1.plot(xs,ys,'.')\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    ev = sim.GetStatus(pa_spikes[1])[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "\n",
    "    ev = pa_spikes[0][0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError\n",
    "\n",
    "# The most common occurence of cell ID is the most active cell\n",
    "# This is plotted to see what the maximally active cell is like, to check for any over-excitation\n",
    "    \n",
    "#occurence_count = Counter(sp)\n",
    "#ring_2_cell = occurence_count.most_common(5)[0][0]\n",
    "\n",
    "spktms = t[sp==ring_2_cell]\n",
    "spktms = (spktms//20)*20\n",
    "spktms=spktms[1:]\n",
    "    \n",
    "xs = pos_x[np.where(np.isin(time, spktms))]\n",
    "ys = pos_y[np.where(np.isin(time, spktms))]\n",
    "\n",
    "ax2.set_title(\"PA Cells (Y_60-axis)\")\n",
    "ax2.plot(pos_x,pos_y)\n",
    "ax2.plot(xs,ys,'.')\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    ev = sim.GetStatus(pa_spikes[2])[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "\n",
    "    ev = pa_spikes[0][0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError\n",
    "\n",
    "# The most common occurence of cell ID is the most active cell\n",
    "# This is plotted to see what the maximally active cell is like, to check for any over-excitation\n",
    "    \n",
    "#occurence_count = Counter(sp)\n",
    "#ring_3_cell = occurence_count.most_common(5)[0][0]\n",
    "\n",
    "spktms = t[sp==ring_3_cell]\n",
    "spktms = (spktms//20)*20\n",
    "spktms=spktms[1:]\n",
    "    \n",
    "xs = pos_x[np.where(np.isin(time, spktms))]\n",
    "ys = pos_y[np.where(np.isin(time, spktms))]\n",
    "\n",
    "ax3.set_title(\"PA Cells (Y_120-axis)\")\n",
    "ax3.plot(pos_x,pos_y)\n",
    "ax3.plot(xs,ys,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a53f495-9f39-404f-9941-af8253fc304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PA ring activity\n",
    "\n",
    "plot_velocity = False\n",
    "plot_acceleration = False\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(25,24))\n",
    "grid_fig, grid_axis = plt.subplots(1,1, figsize=(25,8))\n",
    "grid_axis2 = grid_axis.twinx()\n",
    "\n",
    "if plot_velocity:\n",
    "\n",
    "    pyramid_fig, pyramid_axis = plt.subplots(1,1, figsize=(25,8))\n",
    "    pyramid_axis2 = pyramid_axis.twinx()\n",
    "\n",
    "if plot_acceleration:\n",
    "\n",
    "    pyramid_acceleration_fig, pyramid_acceleration_axis = plt.subplots(1,1, figsize=(25,8))\n",
    "    pyramid_acceleration_axis2 = pyramid_acceleration_axis.twinx()\n",
    "\n",
    "time_start = 0\n",
    "time_end = sim_len // 8\n",
    "\n",
    "colours = ['blue', 'orange', 'green']\n",
    "\n",
    "graph_time = np.array(time)\n",
    "graph_time = graph_time[graph_time < time_end][1:]\n",
    "\n",
    "offsets = [0, Y_plus_60_offset, Y_plus_120_offset]\n",
    "\n",
    "velocity_components = [Y_input_total[:len(graph_time)], Y_plus_60_input_total[:len(graph_time)], Y_plus_120_input_total[:len(graph_time)]]\n",
    "\n",
    "for i, colour, axis, offset, velocity_component in zip(range(len(axes)), colours, axes, offsets, velocity_components):\n",
    "    \n",
    "    if simulate_or_load == 'simulate':\n",
    "\n",
    "        ev = sim.GetStatus(pa_spikes[i])[0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    elif simulate_or_load == 'load':\n",
    "\n",
    "        ev = pa_spikes[i][0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError\n",
    "    \n",
    "    t = t[t < time_end]\n",
    "    \n",
    "    neuron_index = sp - np.min(sp)\n",
    "    \n",
    "    neuron_index = neuron_index[:len(t)] + i * N_pa_cells_per_ring\n",
    "    \n",
    "    ax_twin = axis.twinx()\n",
    "    \n",
    "    print(np.mean(np.diff(time)))\n",
    "    print(velocity_component.shape)\n",
    "    \n",
    "    positive_component = velocity_component[velocity_component > 0]\n",
    "    positive_time = graph_time[velocity_component > 0]\n",
    "    \n",
    "    negative_component = velocity_component[velocity_component < 0]\n",
    "    negative_time = graph_time[velocity_component < 0]\n",
    "    \n",
    "    stationary_component = velocity_component[np.abs(velocity_component) < 2]\n",
    "    stationary_time = graph_time[np.abs(velocity_component) < 2]\n",
    "    \n",
    "    axis.scatter(t, neuron_index, alpha = 0.7, c = colour, label = 'PA Cell Spikes')\n",
    "    ax_twin.scatter(graph_time[20:], velocity_component[20:], c = 'black', label = 'Velocity ?')\n",
    "    ax_twin.scatter(positive_time[20:], positive_component[20:], alpha = 0.7, c = 'lime', label = 'Velocity +')\n",
    "    ax_twin.scatter(negative_time[20:], negative_component[20:], alpha = 0.7, c = 'red', label = 'Velocity -')\n",
    "    ax_twin.scatter(stationary_time[20:], stationary_component[20:], alpha = 0.7, c = 'purple', label = 'Velocity 0')\n",
    "    axis.set_ylabel(\"Neuron Index\")\n",
    "    ax_twin.set_ylabel(\"Velocity\")\n",
    "    axis.set_xlabel(\"Time (ms)\")\n",
    "    \n",
    "    axis.set_title(f\"Ring {i}\")\n",
    "    \n",
    "    axis.legend()\n",
    "    ax_twin.legend(loc = 'upper left')\n",
    "    \n",
    "    neuron_index = sp - np.min(sp)\n",
    "    neuron_index = neuron_index[:len(t)]\n",
    "    \n",
    "    grid_axis.scatter(t, neuron_index, alpha = 0.7, c = colour, label = f\"Ring {i}\")\n",
    "    \n",
    "    grid_axis2.scatter(graph_time[20:], velocity_component[20:], c = colour)\n",
    "    \n",
    "    grid_axis.legend()\n",
    "    \n",
    "combined_components = np.sum(np.array(velocity_components), axis = 0)\n",
    "\n",
    "grid_axis2.scatter(graph_time[20:],  velocity_magnitude[20:len(graph_time)], c = 'purple', label = 'Original V Mag') \n",
    "grid_axis2.scatter(graph_time[20:],  combined_components[20:len(graph_time)], c = 'red',label = 'Sum V Components')\n",
    "grid_axis2.legend(loc = 'upper left')\n",
    "grid_axis.set_ylabel(\"Neuron Index\")\n",
    "grid_axis2.set_ylabel(\"Velocity\")\n",
    "grid_axis.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    ev = sim.GetStatus(pyramidal_spikes)[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "\n",
    "    ev = pyramidal_spikes[0]['events']\n",
    "    sp = np.array(ev['senders'])\n",
    "    t = ev['times']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError\n",
    "\n",
    "t = t[t < time_end]\n",
    "\n",
    "if plot_velocity:\n",
    "\n",
    "    neuron_index = sp - np.min(sp)\n",
    "\n",
    "    neuron_index = neuron_index[:len(t)]\n",
    "\n",
    "    pyramid_axis.scatter(t, neuron_index, label = \"Grid Cell Spikes\")\n",
    "    pyramid_axis2.plot(graph_time, velocity_components[0], c = colours[0], label = 'Y Velocity')\n",
    "    pyramid_axis2.plot(graph_time, velocity_components[1], c = colours[1], label = 'Y + 60 Velocity')\n",
    "    pyramid_axis2.plot(graph_time, velocity_components[2], c = colours[2], label = 'Y + 120 Velocity')\n",
    "    pyramid_axis2.scatter(graph_time,  velocity_magnitude[:len(graph_time)], c = 'purple', label = 'Original V Mag') \n",
    "    pyramid_axis2.scatter(graph_time,  combined_components[:len(graph_time)], c = 'red',label = 'Sum V Components')\n",
    "\n",
    "    pyramid_axis.set_ylabel(\"Neuron Index\")\n",
    "    pyramid_axis2.set_ylabel(\"Velocity\")\n",
    "    pyramid_axis.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "    pyramid_axis.legend()\n",
    "    pyramid_axis2.legend(loc = 'upper left')\n",
    "\n",
    "if plot_acceleration:\n",
    "\n",
    "    t = t[t < time_end]\n",
    "\n",
    "    neuron_index = sp - np.min(sp)\n",
    "\n",
    "    neuron_index = neuron_index[:len(t)]\n",
    "\n",
    "    acceleration_magnitude = np.diff(velocity_magnitude)\n",
    "\n",
    "    acceleration_components = [np.diff(x) for x in velocity_components]\n",
    "\n",
    "    pyramid_acceleration_axis.scatter(t, neuron_index, label = \"Grid Cell Spikes\")\n",
    "    pyramid_acceleration_axis2.plot(graph_time[:-1], acceleration_components[0], c = colours[0], label = 'Y Acceleration')\n",
    "    pyramid_acceleration_axis2.plot(graph_time[:-1], acceleration_components[1], c = colours[1], label = 'Y + 60 Acceleration')\n",
    "    pyramid_acceleration_axis2.plot(graph_time[:-1], acceleration_components[2], c = colours[2], label = 'Y + 120 Acceleration')\n",
    "    pyramid_acceleration_axis2.scatter(graph_time[:-1],  acceleration_magnitude[:len(graph_time[:-1])], c = 'purple', label = 'Original Acc Mag')\n",
    "\n",
    "    pyramid_acceleration_axis.set_ylabel(\"Neuron Index\")\n",
    "    pyramid_acceleration_axis2.set_ylabel(\"Acceleration\")\n",
    "    pyramid_acceleration_axis.set_xlabel(\"Time (ms)\")\n",
    "\n",
    "    pyramid_acceleration_axis.legend()\n",
    "    pyramid_acceleration_axis2.legend(loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f3794-af82-4ba2-ac9d-f81ad11212d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot excitatory ring activity\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(25,24))\n",
    "\n",
    "#time_start = 0\n",
    "#time_end = sim_len# // 8\n",
    "\n",
    "colours = ['blue', 'orange', 'green']\n",
    "\n",
    "offsets = [0, np.radians(60), np.radians(120)]\n",
    "\n",
    "for i, colour, axis, offset, velocity_component in zip(range(len(axes)), colours, axes, offsets, velocity_components):\n",
    "    \n",
    "    if simulate_or_load == 'simulate':\n",
    "\n",
    "        ev = sim.GetStatus(exc_spikes[i])[0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    elif simulate_or_load == 'load':\n",
    "\n",
    "        ev = exc_spikes[i][0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError\n",
    "    \n",
    "    neuron_index = sp - np.min(sp)\n",
    "    \n",
    "    t = t[t < time_end]\n",
    "    neuron_index = neuron_index[:len(t)] + i * N_ex\n",
    "    \n",
    "    ax_twin = axis.twinx()\n",
    "    \n",
    "    positive_component = velocity_component[velocity_component > 0]\n",
    "    positive_time = graph_time[velocity_component > 0]\n",
    "    \n",
    "    negative_component = velocity_component[velocity_component < 0]\n",
    "    negative_time = graph_time[velocity_component < 0]\n",
    "    \n",
    "    stationary_component = velocity_component[np.abs(velocity_component) < 2]\n",
    "    stationary_time = graph_time[np.abs(velocity_component) < 2]\n",
    "    \n",
    "    axis.scatter(t, neuron_index, alpha = 0.7, c = colour)\n",
    "    ax_twin.scatter(graph_time[20:], velocity_component[20:], c = 'black')\n",
    "    ax_twin.scatter(positive_time[20:], positive_component[20:], alpha = 0.7, c = 'lime')\n",
    "    ax_twin.scatter(negative_time[20:], negative_component[20:], alpha = 0.7, c = 'red')\n",
    "    ax_twin.scatter(stationary_time[20:], stationary_component[20:], alpha = 0.7, c = 'purple')\n",
    "    \n",
    "    axis.set_title(f\"Ring {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1381a-ed6f-4cf3-89eb-29d16342b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot excitatory ring activity vs position\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(25,24))\n",
    "\n",
    "#time_start = 0\n",
    "#time_end = sim_len# // 8\n",
    "\n",
    "colours = ['blue', 'orange', 'green']\n",
    "\n",
    "offsets = [0, np.radians(60), np.radians(120)]\n",
    "\n",
    "#Y_input_total_distance = scipy.integrate.cumulative_trapezoid(Y_input_total, dx = 20, initial = 0)#[:len(graph_time)]\n",
    "#Y_plus_60_input_total_distance = scipy.integrate.cumulative_trapezoid(Y_plus_60_input_total, dx = 20, initial = 0)#[:len(graph_time)]\n",
    "#Y_plus_120_input_total_distance = scipy.integrate.cumulative_trapezoid(Y_plus_120_input_total, dx = 20, initial = 0)#[:len(graph_time)]\n",
    "\n",
    "Y_input_total_distance = (np.sin(np.arctan2(pos_y, pos_x) + offsets[0]) * np.sqrt(pos_x ** 2 + pos_y ** 2))[:len(graph_time)]\n",
    "Y_plus_60_input_total_distance = (np.cos(np.arctan2(pos_y, pos_x) + offsets[1]) * np.sqrt(pos_x ** 2 + pos_y ** 2))[:len(graph_time)]\n",
    "Y_plus_120_input_total_distance = (np.cos(np.arctan2(pos_y, pos_x) + offsets[2]) * np.sqrt(pos_x ** 2 + pos_y ** 2))[:len(graph_time)]\n",
    "\n",
    "print(len(Y_input_total))\n",
    "print(len(Y_input_total_distance))\n",
    "print(len(graph_time))\n",
    "\n",
    "distance_components = [Y_input_total_distance, Y_plus_60_input_total_distance, Y_plus_120_input_total_distance]\n",
    "\n",
    "for i, colour, axis, offset, position_component in zip(range(len(axes)), colours, axes, offsets, distance_components):\n",
    "    \n",
    "    print(len(position_component))\n",
    "    \n",
    "    if simulate_or_load == 'simulate':\n",
    "\n",
    "        ev = sim.GetStatus(exc_spikes[i])[0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    elif simulate_or_load == 'load':\n",
    "\n",
    "        ev = exc_spikes[i][0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError\n",
    "    \n",
    "    neuron_index = sp - np.min(sp)\n",
    "    \n",
    "    t = t[t < time_end]\n",
    "    neuron_index = neuron_index[:len(t)] + i * N_ex\n",
    "    \n",
    "    ax_twin = axis.twinx()\n",
    "    \n",
    "    positive_component = position_component[position_component > 0]\n",
    "    positive_time = graph_time[position_component > 0]\n",
    "    \n",
    "    negative_component = position_component[position_component < 0]\n",
    "    negative_time = graph_time[position_component < 0]\n",
    "    \n",
    "    stationary_component = position_component[np.abs(position_component) < 2]\n",
    "    stationary_time = graph_time[np.abs(position_component) < 2]\n",
    "    \n",
    "    axis.scatter(t, neuron_index, alpha = 0.7, c = colour)\n",
    "    ax_twin.scatter(graph_time[20:], position_component[20:], c = 'black')\n",
    "    ax_twin.scatter(positive_time[20:], positive_component[20:], alpha = 0.7, c = 'lime')\n",
    "    ax_twin.scatter(negative_time[20:], negative_component[20:], alpha = 0.7, c = 'red')\n",
    "    ax_twin.scatter(stationary_time[20:], stationary_component[20:], alpha = 0.7, c = 'purple')\n",
    "    \n",
    "    axis.set_title(f\"Ring {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4654a3-ea11-4acb-9600-272b0b1eda36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,3, figsize=(24,16), sharey = True)\n",
    "\n",
    "#unique_t = np.unique(t)\n",
    "\n",
    "for i, axis_pair, position_components in zip(range(len(axes.T)), axes.T, distance_components):\n",
    "    \n",
    "    if simulate_or_load == 'simulate':\n",
    "\n",
    "        ev = sim.GetStatus(exc_spikes[i])[0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    elif simulate_or_load == 'load':\n",
    "\n",
    "        ev = exc_spikes[i][0]['events']\n",
    "        sp = np.array(ev['senders'])\n",
    "        t = ev['times']\n",
    "\n",
    "    else:\n",
    "\n",
    "        raise ValueError\n",
    "    \n",
    "    rounded_timestamps = np.round(t // 20).astype('int') * 20\n",
    "    \n",
    "    rounded_unique_timestamps = np.unique(rounded_timestamps)\n",
    "    \n",
    "    position_timestamps = np.arange(20, max(rounded_timestamps)+20, step = 20)\n",
    "    \n",
    "    #print(position_timestamps)\n",
    "    \n",
    "    mean_neuron_index_per_timestep = np.empty(shape = (len(rounded_unique_timestamps)))\n",
    "    \n",
    "    #print(rounded_timestamps)\n",
    "    #print(rounded_unique_timestamps)\n",
    "    \n",
    "    neuron_index = sp - np.min(sp)\n",
    "    \n",
    "    t = t[t < time_end]\n",
    "    \n",
    "    neuron_index = neuron_index[:len(t)] + i * N_ex\n",
    "    \n",
    "    for i, timestamp in enumerate(rounded_unique_timestamps):\n",
    "        \n",
    "        subset_neurons = neuron_index[rounded_timestamps == timestamp]\n",
    "        \n",
    "        mean_neuron_index_per_timestep[i] = np.mean(subset_neurons)\n",
    "    \n",
    "    unwrapped_neuron_index = np.unwrap(mean_neuron_index_per_timestep, period = N_ex)\n",
    "    \n",
    "    #unwrapped_neuron_index[unwrapped_neuron_index % np.max(unwrapped_neuron_index) == 0] = unwrapped_neuron_index[unwrapped_neuron_index % np.max(unwrapped_neuron_index) == 0] + (unwrapped_neuron_index[unwrapped_neuron_index % np.max(unwrapped_neuron_index) == 0] - 120)\n",
    "    \n",
    "    #print(len(unwrapped_neuron_index))\n",
    "    #print(unwrapped_neuron_index.shape)\n",
    "    #print(len(position_component))\n",
    "    \n",
    "    #binned_spikes = np.histogram(unwrapped_neuron_index, bins = len(position_component))\n",
    "    \n",
    "    positions_with_at_least_one_spike = position_component[np.isin(position_timestamps, rounded_unique_timestamps)]\n",
    "    \n",
    "    print(len(positions_with_at_least_one_spike))\n",
    "    \n",
    "    result = pearsonr(positions_with_at_least_one_spike, unwrapped_neuron_index)\n",
    "    \n",
    "    print(f\"Pearson R: {result[0]}, P-Value: {result[1]}\")\n",
    "    \n",
    "    # To be fair, I think the 'model-fitting' R2 might be more appropriate i.e. Sum Square Residuals/Sum Square Total, since the\n",
    "    # ring attractor is trying to model the position changes via neural velocity integration\n",
    "    \n",
    "    residuals = unwrapped_neuron_index - positions_with_at_least_one_spike\n",
    "    \n",
    "    variance = positions_with_at_least_one_spike - np.mean(positions_with_at_least_one_spike)\n",
    "    \n",
    "    r2 = 1 - np.sum(residuals ** 2) / np.sum(variance ** 2)\n",
    "    \n",
    "    # No, it is meaningless, since the neuron index does not map onto a unit of distance a priori. Representation of distance is\n",
    "    # an emergent property, so a scaling scalar cannot be used either\n",
    "    \n",
    "    #print(f\"R-squared: {r2}\")\n",
    "    \n",
    "    r2_for_subsets = False    \n",
    "    \n",
    "    ### Work in progress: trying to calculate R2 for subsets of data, to hopefully show reducing correlation as run progresses (drift)\n",
    "    \n",
    "    if r2_for_subsets:\n",
    "    \n",
    "        bins = 10\n",
    "\n",
    "        bin_edges = np.round(np.linspace(0, len(position_component), num = bins+1)).astype('int')[1:]\n",
    "\n",
    "        print(bin_edges)\n",
    "\n",
    "        for i, edge in enumerate(bin_edges):\n",
    "\n",
    "            positions_in_bin = position_component[i*edge:(i+1)*edge]\n",
    "\n",
    "            #timestamps_in_bin = position_timestamps[i*edge < position_timestamps <= (i+1)*edge]\n",
    "            timestamps_in_bin = position_timestamps[i*edge:(i+1)*edge]\n",
    "            #timestamps_in_bin = position_timestamps[(i*edge < position_timestamps) & (position_timestamps <= (i+1)*edge)]\n",
    "\n",
    "            assert len(positions_in_bin) == len(timestamps_in_bin)\n",
    "\n",
    "            #rounded_unique_timestamps_in_bin = rounded_unique_timestamps[i*edge < position_timestamps <= (i+1)*edge]\n",
    "            #rounded_unique_timestamps_in_bin = rounded_unique_timestamps[i*edge:(i+1)*edge]\n",
    "\n",
    "            rounded_unique_timestamps_in_bin_index = (i*edge < rounded_unique_timestamps) & (rounded_unique_timestamps <= (i+1)*edge)\n",
    "\n",
    "            rounded_unique_timestamps_in_bin = rounded_unique_timestamps[rounded_unique_timestamps_in_bin_index]\n",
    "\n",
    "            neurons_in_bin = unwrapped_neuron_index[rounded_unique_timestamps_in_bin_index]\n",
    "\n",
    "            print(edge)\n",
    "            print(len(positions_in_bin))\n",
    "            print(len(timestamps_in_bin))\n",
    "            print(len(rounded_unique_timestamps_in_bin))\n",
    "            print(len(neurons_in_bin))\n",
    "\n",
    "            positions_in_bin_with_at_least_one_spike = positions_in_bin[np.isin(timestamps_in_bin, rounded_unique_timestamps_in_bin)]\n",
    "\n",
    "            print(len(positions_in_bin_with_at_least_one_spike))\n",
    "\n",
    "            print(f\"Bin {i+1}, R = {pearsonr(positions_in_bin_with_at_least_one_spike, neurons_in_bin)}\")\n",
    "    \n",
    "    bins = 100\n",
    "    \n",
    "    bin_edges = np.round(np.linspace(0, len(position_component), num = bins+1)).astype('int')[1:]\n",
    "    \n",
    "    window_length = bin_edges[0]\n",
    "    \n",
    "    print(bin_edges)\n",
    "    \n",
    "    cumulative_r_value = np.empty(shape = (bins))\n",
    "    \n",
    "    for i in range(len(bin_edges)):\n",
    "        \n",
    "        cumulative_r_value[i] = pearsonr(positions_with_at_least_one_spike[0:(i+1)*window_length], unwrapped_neuron_index[0:(i+1)*window_length])[0]\n",
    "        \n",
    "        #print(cumulative_r_value[i])\n",
    "        \n",
    "        #print(f\"Bin {i+1}, Sample {i*window_length}:{(i+1)*window_length}, R = {pearsonr(positions_with_at_least_one_spike[0:(i+1)*window_length], unwrapped_neuron_index[0:(i+1)*window_length])}\")\n",
    "    \n",
    "    mean_cumulative_r = np.round(np.mean(cumulative_r_value), 2)\n",
    "    \n",
    "    axis_pair[0].plot(np.arange(0, bins), cumulative_r_value)\n",
    "    axis_pair[0].axhline(y = mean_cumulative_r, c = 'red')\n",
    "    axis_pair[0].text(x = np.arange(0, bins)[np.max(bins)//2], y = mean_cumulative_r + 0.02, s = f\"Mean: {mean_cumulative_r}\")\n",
    "    \n",
    "    if i == 0:\n",
    "        \n",
    "        axis_pair[0].set_ylabel(\"Pearson's R, Cumulative\")\n",
    "    \n",
    "    sliding_r_value = np.empty(shape = (bins))\n",
    "    \n",
    "    for i in range(len(bin_edges)):\n",
    "        \n",
    "        sliding_r_value[i] = pearsonr(positions_with_at_least_one_spike[i*window_length:(i+1)*window_length], unwrapped_neuron_index[i*window_length:(i+1)*window_length])[0]\n",
    "    \n",
    "    mean_sliding_r = np.round(np.mean(sliding_r_value), 2)\n",
    "    \n",
    "    axis_pair[1].plot(np.arange(0, bins), sliding_r_value)\n",
    "    axis_pair[1].axhline(y = mean_sliding_r, c = 'red')\n",
    "    axis_pair[1].text(x = np.arange(0, bins)[np.max(bins)//2], y = mean_sliding_r + 0.02, s = f\"Mean: {mean_sliding_r}\")\n",
    "    axis_pair[1].set_xlabel(\"Sample\")\n",
    "    \n",
    "    if i == 0:\n",
    "        \n",
    "        axis_pair[0].set_ylabel(\"Pearson's R, Sliding Window\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc67ab8-e332-4c13-9e73-ab0f3f5c6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot conjunctive activity\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    fig, axes = plt.subplots(3,1, figsize=(25,24))\n",
    "\n",
    "    time_start = 0\n",
    "    time_end = sim_len // 8\n",
    "\n",
    "    left_colours = ['blue', 'orange', 'green']\n",
    "    right_colours = ['cyan', 'red', 'lime']\n",
    "\n",
    "    offsets = [0, np.radians(60), np.radians(120)]\n",
    "\n",
    "    for i, l_colour, r_colour, axis, offset in zip(range(len(axes)), left_colours, right_colours, axes, offsets):\n",
    "\n",
    "        ev = sim.GetStatus(left_cj_spikes[i])[0]['events']\n",
    "        t = ev['times']\n",
    "        sp = ev['senders']\n",
    "\n",
    "        neuron_index = sp - np.min(sp)\n",
    "\n",
    "        t = t[t < time_end]\n",
    "        neuron_index = neuron_index[:len(t)] + i * N_cj\n",
    "\n",
    "        ax_twin = axis.twinx()\n",
    "\n",
    "        velocity_input = velocity_magnitude * np.sin(velocity_angle)\n",
    "\n",
    "        velocity_component = velocity_input * np.cos(velocity_angle - offset)\n",
    "\n",
    "        #velocity_component = velocity_component[:len(t)]\n",
    "\n",
    "        axis.scatter(t, neuron_index, alpha = 0.5, c = l_colour)\n",
    "        #ax_twin.plot(range(0,len(velocity_component)), velocity_component, c = 'red')\n",
    "\n",
    "        ev = sim.GetStatus(right_cj_spikes[i])[0]['events']\n",
    "        t = ev['times']\n",
    "        sp = ev['senders']\n",
    "\n",
    "        neuron_index = sp - np.min(sp)\n",
    "\n",
    "        t = t[t < time_end]\n",
    "        neuron_index = neuron_index[:len(t)] + i * N_cj\n",
    "\n",
    "        ax_twin = axis.twinx()\n",
    "\n",
    "        velocity_input = velocity_magnitude * np.sin(velocity_angle)\n",
    "\n",
    "        velocity_component = velocity_input * np.cos(velocity_angle - offset)\n",
    "\n",
    "        #velocity_component = velocity_component[:len(t)]\n",
    "\n",
    "        axis.scatter(t, neuron_index, alpha = 0.5, c = r_colour)\n",
    "\n",
    "        axis.set_title(f\"Ring {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b1b69-dc36-44d0-9b69-b4e73a858de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot left conjunctive activity with membrane voltage.\n",
    "# Note that the iaf_psc_alpha model only models sub-threshold dynamics, so the apparent membrane potential will never go above firing threshold\n",
    "# Despite this, it will still generate spikes\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    from matplotlib import cm\n",
    "\n",
    "    fig, axes = plt.subplots(3,1, figsize=(25,24))\n",
    "\n",
    "    time_start = 0\n",
    "    time_end = sim_len // 8\n",
    "\n",
    "    colour_index = np.linspace(0, 1, num = N_ex)\n",
    "    left_colours = cm.get_cmap('viridis')(colour_index)\n",
    "    right_colours = cm.get_cmap('plasma')(colour_index)\n",
    "\n",
    "    for i, l_colour, axis, offset, left_cj_ring in zip(range(len(axes)), left_colours, axes, offsets, l):\n",
    "\n",
    "        ev = sim.GetStatus(left_cj_voltage[i])[0]['events']\n",
    "        t = ev['times']\n",
    "        sp = ev['senders']\n",
    "        voltage = ev['V_m']\n",
    "\n",
    "        #for left_cj_index in left_cj_ring:\n",
    "        if True:\n",
    "\n",
    "            left_cj_index = left_cj_ring[0]\n",
    "\n",
    "            target_neuron_indexes = np.argwhere(sp == left_cj_index)\n",
    "\n",
    "            target_neuron_times = t[target_neuron_indexes]\n",
    "\n",
    "            target_neuron_voltages = voltage[target_neuron_indexes]\n",
    "\n",
    "            axis.scatter(target_neuron_times, target_neuron_voltages, alpha = 0.1, color = l_colour)\n",
    "\n",
    "        ev = sim.GetStatus(left_cj_spikes[i])[0]['events']\n",
    "        t = ev['times']\n",
    "        sp = ev['senders']\n",
    "\n",
    "        ax_twin = axis.twinx()\n",
    "\n",
    "        neuron_index = sp - np.min(sp)\n",
    "\n",
    "        neuron_index = neuron_index + i * N_cj\n",
    "\n",
    "        ax_twin.scatter(t, neuron_index, alpha = 0.1, c = 'red')\n",
    "\n",
    "        axis.set_title(f\"Ring {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a64171-56f0-4c7a-bfaf-69805e44204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot right conjunctive activity with membrane voltage.\n",
    "# Note that the iaf_psc_alpha model only models sub-threshold dynamics, so the apparent membrane potential will never go above firing threshold\n",
    "# Despite this, it will still generate spikes\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    fig, axes = plt.subplots(3,1, figsize=(25,24))\n",
    "\n",
    "    for i, r_colour, axis, offset, right_cj_ring in zip(range(len(axes)), right_colours, axes, offsets, r):\n",
    "\n",
    "        ev = sim.GetStatus(right_cj_voltage[i])[0]['events']\n",
    "        t = ev['times']\n",
    "        sp = ev['senders']\n",
    "        voltage = ev['V_m']\n",
    "\n",
    "        #for right_cj_index in right_cj_ring:\n",
    "        if True:\n",
    "\n",
    "            right_cj_index = right_cj_ring[0]\n",
    "\n",
    "            target_neuron_indexes = np.argwhere(sp == right_cj_index)\n",
    "\n",
    "            target_neuron_times = t[target_neuron_indexes]\n",
    "\n",
    "            target_neuron_voltages = voltage[target_neuron_indexes]\n",
    "\n",
    "            axis.scatter(target_neuron_times, target_neuron_voltages, alpha = 0.1, color = r_colour)\n",
    "\n",
    "        ev = sim.GetStatus(right_cj_spikes[i])[0]['events']\n",
    "        t = ev['times']\n",
    "        sp = ev['senders']\n",
    "\n",
    "        ax_twin = axis.twinx()\n",
    "\n",
    "        neuron_index = sp - np.min(sp)\n",
    "\n",
    "        neuron_index = neuron_index + i * N_cj\n",
    "\n",
    "        ax_twin.scatter(t, neuron_index, alpha = 0.1, c = 'green')\n",
    "\n",
    "        axis.set_title(f\"Ring {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2069ae9-0601-49b8-8406-44ca8d5b9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for *any* grid cells\n",
    "\n",
    "if spiral_or_rat == 'spiral':\n",
    "\n",
    "    t = np.arange(0,sim_len,dt)*1.\n",
    "    time = [i * 1. for i in t if i < sim_len]\n",
    "    \n",
    "elif spiral_or_rat == 'rat':\n",
    "\n",
    "    t = rat_dataset['post'].squeeze()\n",
    "    t = t * 1000\n",
    "    \n",
    "    time = t\n",
    "\n",
    "columns = 4\n",
    "\n",
    "rows = N_pyramidals // columns\n",
    "\n",
    "plot_anything = True\n",
    "\n",
    "if rows > 20: # Too many plots ends up larger than the file format can support\n",
    "    \n",
    "    rows = 20\n",
    "\n",
    "if plot_anything is True:\n",
    "    \n",
    "    fig, axes = plt.subplots(rows,columns,figsize=(columns * 12, rows * 15),facecolor='w')\n",
    "\n",
    "    plots = axes.flatten()\n",
    "\n",
    "if simulate_or_load == 'simulate':\n",
    "\n",
    "    ev = sim.GetStatus(pyramidal_spikes)[0]['events']\n",
    "    \n",
    "elif simulate_or_load == 'load':\n",
    "\n",
    "    ev = pyramidal_spikes[0]['events']\n",
    "    \n",
    "else:\n",
    "    \n",
    "    raise ValueError\n",
    "\n",
    "t = ev['times']\n",
    "sp = ev['senders']\n",
    "\n",
    "for i, cell in enumerate(pyramidal_cells):\n",
    "\n",
    "    spktms1 = t[sp==cell]\n",
    "    spktms1 = (spktms1//20)*20\n",
    "    spktms1=spktms1[1:]\n",
    "\n",
    "    xs = np.empty((len(spktms1)))\n",
    "    ys = np.empty((len(spktms1)))\n",
    "        \n",
    "    xs = pos_x[np.where(np.isin(time, spktms1))]\n",
    "    ys = pos_y[np.where(np.isin(time, spktms1))]\n",
    "    \n",
    "    if plot_anything is True and i < (rows*columns):\n",
    "\n",
    "        plots[i].set_title(\"Pyramidal Cell Spiking #{}\".format(cell))\n",
    "        plots[i].plot(pos_x,pos_y)\n",
    "        plots[i].plot(xs,ys,'.')\n",
    "        \n",
    "    print(f\"Cell {cell}/{max(pyramidal_cells)} done\", end = '\\r')\n",
    "\n",
    "if plot_anything is True:\n",
    "        \n",
    "    plt.savefig(f\"{rows*columns}_pyramidal_cells.png\", bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327bd73a-fed4-4717-8d2a-64d9e2f79920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps based on spike plots\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "plot_anything = True\n",
    "\n",
    "columns = 4\n",
    "\n",
    "rows = int(np.ceil((N_pyramidals / columns))) #N_pyramidals // rows\n",
    "\n",
    "if rows > 20: # Too many plots ends up larger than the file format can support\n",
    "    \n",
    "    rows = 20\n",
    "\n",
    "if plot_anything is True:\n",
    "    \n",
    "    fig, axes = plt.subplots(rows,columns,figsize=(columns * 15, rows * 15),facecolor='w')\n",
    "\n",
    "    plots = axes.flatten()\n",
    "\n",
    "    if 100 < N_pyramidals: # If there are too many plots, they still need to be generated to calculate grid score. Therefore, repeat the axes\n",
    "                              # so that plots are overwritten as needed\n",
    "\n",
    "        plots = np.repeat(plots, N_pyramidals // 100)\n",
    "\n",
    "        for i in range(N_pyramidals % 100):\n",
    "\n",
    "            plots = np.append(plots, plots[i])\n",
    "\n",
    "from scipy.ndimage import gaussian_filter, uniform_filter\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.signal import correlate2d\n",
    "\n",
    "bin_size_cm = 3 # 3x3cm bins for Sargolini paper\n",
    "rate_map_sigma = 3\n",
    "\n",
    "normalised_rate_maps = []\n",
    "\n",
    "max_cell_index = max(pyramidal_cells)\n",
    "\n",
    "start = process_time()\n",
    "\n",
    "for i, cell in enumerate(pyramidal_cells):\n",
    "\n",
    "    spktms1 = t[sp==cell]\n",
    "    spktms1 = (spktms1//20)*20\n",
    "    spktms1=spktms1[1:]\n",
    "        \n",
    "    xs = pos_x[np.where(np.isin(time, spktms1))]\n",
    "    ys = pos_y[np.where(np.isin(time, spktms1))]\n",
    "    \n",
    "    bins = int(max(np.sqrt(xs**2 + ys**2)) // bin_size_cm)\n",
    "    \n",
    "    if len(xs > 1) and len (ys > 1):\n",
    "    \n",
    "        binned_firing = np.histogram2d(-ys/max(-ys), xs/max(xs), bins = bins, density = True)[0]\n",
    "\n",
    "        smoothed_binned_firing = gaussian_filter(binned_firing, sigma = 3)\n",
    "        smooth_plot = plots[i].imshow(smoothed_binned_firing, cmap = 'jet')\n",
    "        \n",
    "        normalised_rate_map = np.array(smoothed_binned_firing/smoothed_binned_firing.max())\n",
    "        \n",
    "        normalised_rate_maps.append(normalised_rate_map)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        normalised_rate_map = np.zeros(shape = (bins, bins))\n",
    "        \n",
    "        normalised_rate_maps.append(normalised_rate_map)\n",
    "        \n",
    "        print(f\"Cell {cell} (i = {i}) appears to have no spikes. This may be an error.\")\n",
    "    \n",
    "    if plot_anything is True:\n",
    "    \n",
    "        plots[i].set_title(\"Pyramidal Cell Rate Heatmap #{}\".format(cell))\n",
    "        plots[i].imshow(binned_firing)\n",
    "        plots[i].set_axis_off()\n",
    "    \n",
    "    print(f\"Cell {cell}/{max_cell_index} done\", end = '\\r')\n",
    "\n",
    "end = process_time()\n",
    "\n",
    "print(\"Time taken: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afce7e-5641-495d-a67b-eaf2cdd84dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now turn these into autocorrelograms\n",
    "\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.ndimage import shift\n",
    "\n",
    "plot_anything = True\n",
    "\n",
    "columns = 4\n",
    "\n",
    "rows = int(np.ceil((N_pyramidals / columns))) #N_pyramidals // rows\n",
    "\n",
    "if rows > 20: # Too many plots ends up larger than the file format can support\n",
    "    \n",
    "    rows = 20\n",
    "\n",
    "if plot_anything is True:\n",
    "    \n",
    "    fig, axes = plt.subplots(rows,columns,figsize=(columns * 15, rows * 15),facecolor='w')\n",
    "\n",
    "    plots = axes.flatten()\n",
    "\n",
    "    if 100 < N_pyramidals: # If there are too many plots, they still need to be generated to calculate grid score. Therefore, repeat the axes\n",
    "                              # so that plots are overwritten as needed\n",
    "\n",
    "        plots = np.repeat(plots, N_pyramidals // 100)\n",
    "\n",
    "        for i in range(N_pyramidals % 100):\n",
    "\n",
    "            plots = np.append(plots, plots[i])\n",
    "\n",
    "start = process_time()\n",
    "\n",
    "for i, normalised_rate_map in enumerate(normalised_rate_maps):\n",
    "\n",
    "    autocorrelogram = np.zeros(shape = (normalised_rate_map.shape[0] * 2 - 1, normalised_rate_map.shape[1] * 2 - 1))\n",
    "\n",
    "    for shift_x in range(-normalised_rate_map.shape[0], normalised_rate_map.shape[0]):\n",
    "\n",
    "        for shift_y in range(-normalised_rate_map.shape[1], normalised_rate_map.shape[1]):\n",
    "\n",
    "            shifted_rate_map = np.roll(normalised_rate_map, (shift_x, shift_y), axis = (0,1))\n",
    "            normalised_rate_map_to_shift = normalised_rate_map\n",
    "\n",
    "            if shift_x == 0 and shift_y == 0:\n",
    "\n",
    "                normalised_rate_map_shifted = normalised_rate_map_to_shift\n",
    "\n",
    "            elif shift_x != 0 and shift_y == 0:\n",
    "\n",
    "                if shift_x < 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[:shift_x, :]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_to_shift[:shift_x, :]\n",
    "\n",
    "                elif shift_x > 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[shift_x:, :]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_to_shift[shift_x:, :]\n",
    "\n",
    "            elif shift_y != 0 and shift_x == 0:\n",
    "\n",
    "                if shift_y < 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[:, -shift_y:]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_to_shift[:, -shift_y:]\n",
    "\n",
    "                elif shift_y > 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[:, :-shift_y]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_to_shift[:, :-shift_y]\n",
    "\n",
    "            if shift_x != 0 and shift_y != 0:\n",
    "\n",
    "                if shift_x < 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[:shift_x, :]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_to_shift[:shift_x, :]\n",
    "\n",
    "                elif shift_x > 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[shift_x:, :]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_to_shift[shift_x:, :]\n",
    "\n",
    "                if shift_y < 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[:, -shift_y:]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_shifted[:, -shift_y:]\n",
    "\n",
    "                elif shift_y > 0:\n",
    "\n",
    "                    shifted_rate_map = shifted_rate_map[:, :-shift_y]\n",
    "                    normalised_rate_map_shifted = normalised_rate_map_shifted[:, :-shift_y]\n",
    "\n",
    "            if len(shifted_rate_map.flatten()) > 2:\n",
    "\n",
    "                correlation = np.cov(normalised_rate_map_shifted.flatten(), shifted_rate_map.flatten())[0][1]\n",
    "\n",
    "                if correlation < 0.002:\n",
    "\n",
    "                    correlation = 0\n",
    "\n",
    "            else:\n",
    "\n",
    "                correlation = np.nan\n",
    "\n",
    "            autocorrelogram[shift_x + normalised_rate_map.shape[0]-1, shift_y + normalised_rate_map.shape[1]-1] = correlation\n",
    "    \n",
    "    if plot_anything is True:\n",
    "    \n",
    "        plots[i].set_title(\"Pyramidal Cell Rate Heatmap #{}\".format(cell))\n",
    "        plots[i].imshow(autocorrelogram, cmap = 'plasma')\n",
    "        plots[i].set_axis_off()\n",
    "    \n",
    "    print(f\"Cell {cell}/{max_cell_index} done\", end = '\\r')\n",
    "\n",
    "end = process_time()\n",
    "\n",
    "print(\"Time taken: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a14eda-d76d-46de-b740-88dc5b55a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find some important details for use in the Sargolini gridness score\n",
    "\n",
    "# Find the central circle of the autocorrelogram\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage import color\n",
    "from skimage.morphology import binary_erosion, disk\n",
    "from skimage.filters.rank import maximum\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "heatmap_size = 4\n",
    "\n",
    "# fig, ax = plt.subplots(1,1, figsize = (heatmap_size, heatmap_size))\n",
    "\n",
    "# greyplot = ax.pcolormesh(xi, yi, zi.reshape(xi.shape), cmap = 'Greys_r')\n",
    "\n",
    "# plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "# plt.axis('off')\n",
    "# plt.axis('image')\n",
    "\n",
    "# fig = plt.gcf()\n",
    "# fig.canvas.draw()\n",
    "\n",
    "# greymap = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "\n",
    "# greymap = greymap.reshape(fig.canvas.get_width_height() + (3,))\n",
    "\n",
    "# greymap = color.rgb2gray(greymap)\n",
    "\n",
    "autocorrelogram_mask = autocorrelogram[np.where(np.isnan(autocorrelogram))]\n",
    "\n",
    "autocorrelogram[np.isnan(autocorrelogram)] = 0\n",
    "\n",
    "greymap = autocorrelogram\n",
    "\n",
    "greymap_mask = autocorrelogram_mask\n",
    "\n",
    "threshold = threshold_otsu(greymap)\n",
    "\n",
    "binary = greymap > threshold\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (heatmap_size, heatmap_size))\n",
    "\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "plt.axis('off')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.canvas.draw()\n",
    "\n",
    "ax.imshow(binary, cmap=plt.cm.gray)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize = (heatmap_size, heatmap_size))\n",
    "\n",
    "plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
    "plt.axis('off')\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.canvas.draw()\n",
    "\n",
    "local_maxima = peak_local_max(greymap, num_peaks = 7, min_distance = heatmap_size * 5)\n",
    "\n",
    "print(local_maxima)\n",
    "\n",
    "ax.imshow(greymap)\n",
    "\n",
    "for peak in local_maxima:\n",
    "    \n",
    "    y, x = peak\n",
    "    ax.plot(x, y, 'o')\n",
    "    \n",
    "mean_y = int(np.floor(np.mean(local_maxima[:,0])))\n",
    "mean_x = int(np.floor(np.mean(local_maxima[:,1])))\n",
    "\n",
    "center_threshold = heatmap_size * 10\n",
    "\n",
    "for peak in local_maxima:\n",
    "    \n",
    "    y, x = peak\n",
    "    \n",
    "    if abs(mean_y - y) < center_threshold and abs(mean_x - x) < center_threshold:\n",
    "        \n",
    "        center_y = y\n",
    "        \n",
    "        center_x = x\n",
    "        \n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        center_y = mean_y\n",
    "        \n",
    "        center_x = mean_x\n",
    "\n",
    "ax.plot(center_x, center_y, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a55cdf-c4b0-4b7b-b64d-79e145bcdb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
